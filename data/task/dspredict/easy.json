[
    {
      "challenge_name": "house-prices-advanced-regression-techniques",
      "description": "Challenge:\n# House Prices - Advanced Regression Techniques\n\nPredict sales prices and practice feature engineering, RFs, and gradient boosting\n\n## Competition Description\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\n### Practice Skills\n- Creative feature engineering\n- Advanced regression techniques like random forest and gradient boosting\n\n## Evaluation\n### Goal\nIt is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable.\n\n### Metric\nSubmissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n\n### Submission File Format\nThe file should contain a header and have the following format:\nId,SalePrice\n1461,169000.1\n1462,187724.1233\n1463,175221\netc.\n\nYou can download an example submission file (sample_submission.csv) on the Data page.\n\n## Competition Details\n- **Competition Host**: Kaggle\n- **Prizes & Awards**: Does not award Points or Medals\n- **Participation**: 901,161 Entrants, 4,175 Participants, 4,079 Teams, 18,059 Submissions\n- **Tags**: Regression, Tabular, Root Mean Squared Logarithmic Error\n- **Timeline**: This competition runs indefinitely with a rolling leaderboard\n\nData description:\nHouse Prices - Advanced Regression Techniques\nPredict sales prices and practice feature engineering, RFs, and gradient boosting\n\nDataset Description\nFile descriptions\ntrain.csv - the training set\ntest.csv - the test set\ndata_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\nsample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\n\nData fields\nHere's a brief version of what you'll find in the data description file.\nSalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\nMSSubClass: The building class\nMSZoning: The general zoning classification\nLotFrontage: Linear feet of street connected to property\nLotArea: Lot size in square feet\nStreet: Type of road access\nAlley: Type of alley access\nLotShape: General shape of property\nLandContour: Flatness of the property\nUtilities: Type of utilities available\nLotConfig: Lot configuration\nLandSlope: Slope of property\nNeighborhood: Physical locations within Ames city limits\nCondition1: Proximity to main road or railroad\nCondition2: Proximity to main road or railroad (if a second is present)\nBldgType: Type of dwelling\nHouseStyle: Style of dwelling\nOverallQual: Overall material and finish quality\nOverallCond: Overall condition rating\nYearBuilt: Original construction date\nYearRemodAdd: Remodel date\nRoofStyle: Type of roof\nRoofMatl: Roof material\nExterior1st: Exterior covering on house\nExterior2nd: Exterior covering on house (if more than one material)\nMasVnrType: Masonry veneer type\nMasVnrArea: Masonry veneer area in square feet\nExterQual: Exterior material quality\nExterCond: Present condition of the material on the exterior\nFoundation: Type of foundation\nBsmtQual: Height of the basement\nBsmtCond: General condition of the basement\nBsmtExposure: Walkout or garden level basement walls\nBsmtFinType1: Quality of basement finished area\nBsmtFinSF1: Type 1 finished square feet\nBsmtFinType2: Quality of second finished area (if present)\nBsmtFinSF2: Type 2 finished square feet\nBsmtUnfSF: Unfinished square feet of basement area\nTotalBsmtSF: Total square feet of basement area\nHeating: Type of heating\nHeatingQC: Heating quality and condition\nCentralAir: Central air conditioning\nElectrical: Electrical system\n1stFlrSF: First Floor square feet\n2ndFlrSF: Second floor square feet\nLowQualFinSF: Low quality finished square feet (all floors)\nGrLivArea: Above grade (ground) living area square feet\nBsmtFullBath: Basement full bathrooms\nBsmtHalfBath: Basement half bathrooms\nFullBath: Full bathrooms above grade\nHalfBath: Half baths above grade\nBedroom: Number of bedrooms above basement level\nKitchen: Number of kitchens\nKitchenQual: Kitchen quality\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\nFunctional: Home functionality rating\nFireplaces: Number of fireplaces\nFireplaceQu: Fireplace quality\nGarageType: Garage location\nGarageYrBlt: Year garage was built\nGarageFinish: Interior finish of the garage\nGarageCars: Size of garage in car capacity\nGarageArea: Size of garage in square feet\nGarageQual: Garage quality\nGarageCond: Garage condition\nPavedDrive: Paved driveway\nWoodDeckSF: Wood deck area in square feet\nOpenPorchSF: Open porch area in square feet\nEnclosedPorch: Enclosed porch area in square feet\n3SsnPorch: Three season porch area in square feet\nScreenPorch: Screen porch area in square feet\nPoolArea: Pool area in square feet\nPoolQC: Pool quality\nFence: Fence quality\nMiscFeature: Miscellaneous feature not covered in other categories\nMiscVal: $Value of miscellaneous feature\nMoSold: Month Sold\nYrSold: Year Sold\nSaleType: Type of sale\nSaleCondition: Condition of sale",
      "docker_challenge_path": "/data/house-prices-advanced-regression-techniques",
      "competition_description": "## Competition Description\nAsk a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n\nWith 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n\n### Practice Skills\n- Creative feature engineering\n- Advanced regression techniques like random forest and gradient boosting",
      "evaluation_metric": "### Metric\nSubmissions are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)",
      "dataset_description": "Data description:\nHouse Prices - Advanced Regression Techniques\nPredict sales prices and practice feature engineering, RFs, and gradient boosting\n\nDataset Description\nFile descriptions\ntrain.csv - the training set\ntest.csv - the test set\ndata_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here\nsample_submission.csv - a benchmark submission from a linear regression on year and month of sale, lot square footage, and number of bedrooms\n\nData fields\nHere's a brief version of what you'll find in the data description file.\nSalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\nMSSubClass: The building class\nMSZoning: The general zoning classification\nLotFrontage: Linear feet of street connected to property\nLotArea: Lot size in square feet\nStreet: Type of road access\nAlley: Type of alley access\nLotShape: General shape of property\nLandContour: Flatness of the property\nUtilities: Type of utilities available\nLotConfig: Lot configuration\nLandSlope: Slope of property\nNeighborhood: Physical locations within Ames city limits\nCondition1: Proximity to main road or railroad\nCondition2: Proximity to main road or railroad (if a second is present)\nBldgType: Type of dwelling\nHouseStyle: Style of dwelling\nOverallQual: Overall material and finish quality\nOverallCond: Overall condition rating\nYearBuilt: Original construction date\nYearRemodAdd: Remodel date\nRoofStyle: Type of roof\nRoofMatl: Roof material\nExterior1st: Exterior covering on house\nExterior2nd: Exterior covering on house (if more than one material)\nMasVnrType: Masonry veneer type\nMasVnrArea: Masonry veneer area in square feet\nExterQual: Exterior material quality\nExterCond: Present condition of the material on the exterior\nFoundation: Type of foundation\nBsmtQual: Height of the basement\nBsmtCond: General condition of the basement\nBsmtExposure: Walkout or garden level basement walls\nBsmtFinType1: Quality of basement finished area\nBsmtFinSF1: Type 1 finished square feet\nBsmtFinType2: Quality of second finished area (if present)\nBsmtFinSF2: Type 2 finished square feet\nBsmtUnfSF: Unfinished square feet of basement area\nTotalBsmtSF: Total square feet of basement area\nHeating: Type of heating\nHeatingQC: Heating quality and condition\nCentralAir: Central air conditioning\nElectrical: Electrical system\n1stFlrSF: First Floor square feet\n2ndFlrSF: Second floor square feet\nLowQualFinSF: Low quality finished square feet (all floors)\nGrLivArea: Above grade (ground) living area square feet\nBsmtFullBath: Basement full bathrooms\nBsmtHalfBath: Basement half bathrooms\nFullBath: Full bathrooms above grade\nHalfBath: Half baths above grade\nBedroom: Number of bedrooms above basement level\nKitchen: Number of kitchens\nKitchenQual: Kitchen quality\nTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\nFunctional: Home functionality rating\nFireplaces: Number of fireplaces\nFireplaceQu: Fireplace quality\nGarageType: Garage location\nGarageYrBlt: Year garage was built\nGarageFinish: Interior finish of the garage\nGarageCars: Size of garage in car capacity\nGarageArea: Size of garage in square feet\nGarageQual: Garage quality\nGarageCond: Garage condition\nPavedDrive: Paved driveway\nWoodDeckSF: Wood deck area in square feet\nOpenPorchSF: Open porch area in square feet\nEnclosedPorch: Enclosed porch area in square feet\n3SsnPorch: Three season porch area in square feet\nScreenPorch: Screen porch area in square feet\nPoolArea: Pool area in square feet\nPoolQC: Pool quality\nFence: Fence quality\nMiscFeature: Miscellaneous feature not covered in other categories\nMiscVal: $Value of miscellaneous feature\nMoSold: Month Sold\nYrSold: Year Sold\nSaleType: Type of sale\nSaleCondition: Condition of sale",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering & tree-based models",
          "housing/real_estate",
          "rmsle"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e1",
      "description": "Challenge description:\nPlayground Series - Season 3, Episode 1\nRegression with a Tabular California Housing Dataset\n\nNOTE: You can now create your own synthetic versions of this dataset by forking and running this notebook.\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to last year's Tabular Playground Series. And many thanks to all those who took the time to provide constructive feedback! We're thrilled that there continues to be interest in these types of challenges, and we're continuing the series this year but with a few changes.\nFirst, the series is getting upgraded branding. We've dropped \"Tabular\" from the name because, while we anticipate this series will still have plenty of tabular competitions, we'll also be having some other formats as well. You'll also notice freshly-upgraded (better looking and more fun!) banner and thumbnail images.\nSecond, rather than naming the challenges by month and year, we're moving to a Season-Edition format. This year is Season 3, and each challenge will be a new Edition. We're doing this to have more flexibility. Competitions going forward won't necessarily align with each month like they did in previous years (although some might!), we'll have competitions with different time durations, and we may have multiple competitions running at the same time on occasion.\nRegardless of these changes, the goals of the Playground Series remain the same\u2014to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. We hope we continue to meet this objective!\nTo start the year with some fun, January will be the month of Tabular Tuesday. We're launching four week-long tabular competitions, with each starting Tuesday 00:00 UTC. These will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nRoot Mean Squared Error (RMSE)\nSubmissions are scored on the root mean squared error. RMSE is defined as:\n$$\\textrm{RMSE} =  \\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 }$$\nwhere \\( \\hat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).\nFor each id in the test set, you must predict the value for the target MedHouseVal. The file should contain a header and have the following format:\nid,MedHouseVal\n37137,2.01\n37138,0.92\n37139,1.11\netc.\n\nStart Date- January 3, 2023\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline- January 9, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\nDoes not award Points or Medals\n\nWalter Reade and Ashley Chow. Regression with a Tabular California Housing Dataset. https://kaggle.com/competitions/playground-series-s3e1, 2023. Kaggle.\nCompetition Host Kaggle\n\nData description:\nPlayground Series - Season 3, Episode 1\n\nRegression with a Tabular California Housing Dataset\n\nDataset Description\nNOTE: You can now create your own synthetic versions of this dataset by forking and running this notebook.\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the California Housing Dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; MedHouseVal is the target\ntest.csv - the test dataset; your objective is to predict MedHouseVal\nsample_submission.csv - a sample submission file in the correct format\n\nLicense\nAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e1",
      "competition_description": "Challenge description:\nPlayground Series - Season 3, Episode 1\nRegression with a Tabular California Housing Dataset\n\nNOTE: You can now create your own synthetic versions of this dataset by forking and running this notebook.\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to last year's Tabular Playground Series. And many thanks to all those who took the time to provide constructive feedback! We're thrilled that there continues to be interest in these types of challenges, and we're continuing the series this year but with a few changes.\nFirst, the series is getting upgraded branding. We've dropped \"Tabular\" from the name because, while we anticipate this series will still have plenty of tabular competitions, we'll also be having some other formats as well. You'll also notice freshly-upgraded (better looking and more fun!) banner and thumbnail images.\nSecond, rather than naming the challenges by month and year, we're moving to a Season-Edition format. This year is Season 3, and each challenge will be a new Edition. We're doing this to have more flexibility. Competitions going forward won't necessarily align with each month like they did in previous years (although some might!), we'll have competitions with different time durations, and we may have multiple competitions running at the same time on occasion.\nRegardless of these changes, the goals of the Playground Series remain the same\u2014to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. We hope we continue to meet this objective!\nTo start the year with some fun, January will be the month of Tabular Tuesday. We're launching four week-long tabular competitions, with each starting Tuesday 00:00 UTC. These will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Root Mean Squared Error (RMSE)\nSubmissions are scored on the root mean squared error. RMSE is defined as:\n$$\\textrm{RMSE} =  \\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 }$$\nwhere \\( \\hat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 1\n\nRegression with a Tabular California Housing Dataset\n\nDataset Description\nNOTE: You can now create your own synthetic versions of this dataset by forking and running this notebook.\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the California Housing Dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; MedHouseVal is the target\ntest.csv - the test dataset; your objective is to predict MedHouseVal\nsample_submission.csv - a sample submission file in the correct format\n\nLicense\nAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature_engineering",
          "geospatial",
          "rmse"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e11",
      "description": "Challenge description:\nPlayground Series - Season 3, Episode 11  \nRegression with a Tabular Media Campaign Cost Dataset  \n\nWelcome to the 2023 edition of Kaggle's Playground Series!  \nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!  \nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in March every Tuesday 00:00 UTC, with each competition running for 2 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!  \n\nEvaluation  \nRoot Mean Squared Log Error (RMLSE)  \nSubmissions are scored on the root mean squared log error (RMSLE) (the sklearn mean_squared_log_error with squared=False).  \n\nSubmission File  \nFor each id in the test set, you must predict the value for the target cost. The file should contain a header and have the following format:  \nid,cost  \n360336,99.615  \n360337,87.203  \n360338,101.111  \netc.  \n\nTimeline  \nStart Date - March 20, 2023  \nEntry Deadline - Same as the Final Submission Deadline  \nTeam Merger Deadline - Same as the Final Submission Deadline  \nFinal Submission Deadline - April 3, 2023  \n\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.  \n\nPrizes  \n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \n\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.  \n\nCitation  \nWalter Reade and Ashley Chow. Regression with a Tabular Media Campaign Cost Dataset. https://kaggle.com/competitions/playground-series-s3e11, 2023. Kaggle.  \n\nCompetition Host  \nKaggle  \n\nPrizes & Awards  \nSwag  \nDoes not award Points or Medals  \n\nTags  \nBeginner, Tabular, Regression, Mean Squared Log Error\n\nData description:\nPlayground Series - Season 3, Episode 11\nRegression with a Tabular Media Campaign Cost Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Media Campaign Cost Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; cost is the target\ntest.csv - the test dataset; your objective is to predict cost\nsample_submission.csv - a sample submission file in the correct format\n\nMetadata\nFiles: 3 files\nSize: 49.83 MB\nType: csv\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e11",
      "competition_description": "Challenge description:\nPlayground Series - Season 3, Episode 11  \nRegression with a Tabular Media Campaign Cost Dataset  \n\nWelcome to the 2023 edition of Kaggle's Playground Series!  \nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!  \nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in March every Tuesday 00:00 UTC, with each competition running for 2 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Evaluation  \nRoot Mean Squared Log Error (RMLSE)  \nSubmissions are scored on the root mean squared log error (RMSLE) (the sklearn mean_squared_log_error with squared=False).",
      "dataset_description": "Playground Series - Season 3, Episode 11\nRegression with a Tabular Media Campaign Cost Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Media Campaign Cost Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; cost is the target\ntest.csv - the test dataset; your objective is to predict cost\nsample_submission.csv - a sample submission file in the correct format\n\nMetadata\nFiles: 3 files\nSize: 49.83 MB\nType: csv\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "advertising",
          "rmse"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e13",
      "description": "Challenge description:\nPlayground Series - Season 3, Episode 13: Classification with a Tabular Vector Borne Disease Dataset\n\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in April every Tuesday 00:00 UTC, with each competition running for 2 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nEvaluation\nSubmissions will be evaluated based on MPA@3. Each submission can contain up to 3 predictions (all separated by spaces), and the earlier a correct prediction occurs, the higher score it will receive.\n\nSubmission File\nFor each id in the test set, you must predict the target prognosis. The file should contain a header and have the following format:\nid,prognosis\n707,Dengue West_Nile_fever Malaria\n708,Lyme_disease West_Nile_fever Dengue\n709,Dengue West_Nile_fever Lyme_disease\netc.\n\nTimeline\nStart Date- April 18, 2023\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline- May 1, 2023\n\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nPrizes\n1st Place- Choice of Kaggle merchandise\n2nd Place- Choice of Kaggle merchandise\n3rd Place- Choice of Kaggle merchandise\n\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade, Will Lifferth, and Ashley Chow. Classification with a Tabular Vector Borne Disease Dataset. https://kaggle.com/competitions/playground-series-s3e13, 2023. Kaggle.\n\nCompetition Host: Kaggle\n\nPrizes & Awards\nSwag\nDoes not award Points or Medals\n\nParticipation\n2,553 Entrants\n963 Participants\n934 Teams\n7,765 Submissions\n\nTags\nBeginner\nTabular\nMulticlass Classification\nHealth Conditions\nMAP@{K}\n\nData description:\nPlayground Series - Season 3, Episode 13\nClassification with a Tabular Vector Borne Disease Dataset\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theVector Borne Disease Predictiondataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance. Note that in the original dataset some prognoses contain spaces, but in the competition dataset spaces have been replaced with underscores to work with the MPA@K metric.\nFiles\ntrain.csv- the training dataset;prognosisis the target\ntest.csv- the test dataset; your objective is to predictprognosis\nsample_submission.csv- a sample submission file in the correct format\nMetadata\nLicense Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e13",
      "competition_description": "Challenge description:\nPlayground Series - Season 3, Episode 13: Classification with a Tabular Vector Borne Disease Dataset\n\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in April every Tuesday 00:00 UTC, with each competition running for 2 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Evaluation\nSubmissions will be evaluated based on MPA@3. Each submission can contain up to 3 predictions (all separated by spaces), and the earlier a correct prediction occurs, the higher score it will receive.",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 13\nClassification with a Tabular Vector Borne Disease Dataset\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theVector Borne Disease Predictiondataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance. Note that in the original dataset some prognoses contain spaces, but in the competition dataset spaces have been replaced with underscores to work with the MPA@K metric.\nFiles\ntrain.csv- the training dataset;prognosisis the target\ntest.csv- the test dataset; your objective is to predictprognosis\nsample_submission.csv- a sample submission file in the correct format\nMetadata\nLicense Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "multiclass classification",
          "tabular",
          "feature engineering",
          "epidemiology",
          "map@3"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e14",
      "description": "Challenge description:\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nYour Goal: For this Episode of the Series, your task is to use regression to predict the yield of wild blueberries. Good luck!\nNOTE: You can now create your own synthetic versions of this dataset by forking and running this notebook.\nStart May 1, 2023 Close May 15, 2023\nEvaluation\nSubmissions will be evaluated using Mean Absolute Error (MAE), where each x_i represents the predicted target, y_i represents the ground truth, and n is the number of rows in the test set.\nSubmission File\nFor each id in the test set, you must predict the target yield. The file should contain a header and have the following format:\nid,yield\n15289,6025.194\n15290,1256.223\n15291,357.44\netc.\nTimeline\nStart Date - May 2, 2023\nEntry Deadline - Same as the Final Submission Deadline\nTeam Merger Deadline - Same as the Final Submission Deadline\nFinal Submission Deadline - May 15, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\nCitation\nWalter Reade and Ashley Chow. Regression with a Wild Blueberry Yield Dataset. https://kaggle.com/competitions/playground-series-s3e14, 2023. Kaggle.\nCompetition Host\nKaggle\nPrizes & Awards\nSwag\nDoes not award Points or Medals\nParticipation\n4,197 Entrants\n1,904 Participants\n1,875 Teams\n12,227 Submissions\nTags\nBeginner\nTabular\nRegression\nMean Absolute Error\n\nData description:\nPlayground Series - Season 3, Episode 14\nRegression with a Wild Blueberry Yield Dataset\n\nDataset Description\nNOTE: You can now create your own synthetic versions of this dataset by forking and running this notebook.\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Wild blueberry Yield Prediction Dataset. (Since this is Playground 3.14, it seems like we need a Blueberry Pie joke here?) Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; yield is the target\ntest.csv - the test dataset; your objective is to predict the yield given the other features\nsample_submission.csv - a sample submission file in the correct format\n\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e14",
      "competition_description": "Challenge description:\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nYour Goal: For this Episode of the Series, your task is to use regression to predict the yield of wild blueberries. Good luck!\nNOTE: You can now create your own synthetic versions of this dataset by forking and running this notebook.\nStart May 1, 2023 Close May 15, 2023",
      "evaluation_metric": "Evaluation\nSubmissions will be evaluated using Mean Absolute Error (MAE), where each x_i represents the predicted target, y_i represents the ground truth, and n is the number of rows in the test set.",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 14\nRegression with a Wild Blueberry Yield Dataset\n\nDataset Description\nNOTE: You can now create your own synthetic versions of this dataset by forking and running this notebook.\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Wild blueberry Yield Prediction Dataset. (Since this is Playground 3.14, it seems like we need a Blueberry Pie joke here?) Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; yield is the target\ntest.csv - the test dataset; your objective is to predict the yield given the other features\nsample_submission.csv - a sample submission file in the correct format\n\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "agriculture",
          "mae"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e15",
      "description": "Challenge description:\nFeature Imputation with a Heat Flux DatasetPlayground Series - Season 3, Episode 15Welcome to the 2023 edition of Kaggle's Playground Series!Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!With the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in May every Tuesday 00:00 UTC, with each competition running for 2 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc..Synthetically-Generated DatasetsUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!EvaluationRoot Mean Squared Error (RMSE)Submissions are scored on the root mean squared error. RMSE is defined as:$$\\textrm{RMSE} =  \\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 }$$where \\( \\hat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).Submission FileThis is an imputation problem. You are to predict the missing values of the featurex_e_out [-](with the corresponding rowid). The file should contain a header and have the following format:id,x_e_out[-]4,0.007.0.1210,-0.02etc.TimelineStart Date- May 16, 2023Entry Deadline- Same as the Final Submission DeadlineTeam Merger Deadline- Same as the Final Submission DeadlineFinal Submission Deadline-  May 29, 2023All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.Prizes1st Place - Choice of Kaggle merchandise2nd Place - Choice of Kaggle merchandise3rd Place - Choice of Kaggle merchandisePlease note:In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.CitationWalter Reade and Ashley Chow. Feature Imputation with a Heat Flux Dataset. https://kaggle.com/competitions/playground-series-s3e15, 2023. Kaggle.CiteCompetition HostKagglePrizes & AwardsSwagDoes not award Points or MedalsParticipation2,077 Entrants713 Participants693 Teams5,853 SubmissionsTagsBeginnerTabularPhysicsRegressionRoot Mean Squared Error\n\nData description:\nPlayground Series - Season 3, Episode 15\nFeature Imputation with a Heat Flux Dataset\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on thePredicting Critical Heat Fluxdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nFiles\ndata.csv- the competition dataset; your objective is to impute the missing values of thefeaturex_e_out [-](equilibrium quality)\nsample_submission.csv- a sample submission file in the correct format\nFiles\n2 files\nSize 1.73 MB\nType csv\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e15",
      "competition_description": "Challenge description:\nFeature Imputation with a Heat Flux DatasetPlayground Series - Season 3, Episode 15Welcome to the 2023 edition of Kaggle's Playground Series!Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!With the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in May every Tuesday 00:00 UTC, with each competition running for 2 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc..Synthetically-Generated DatasetsUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "EvaluationRoot Mean Squared Error (RMSE)Submissions are scored on the root mean squared error. RMSE is defined as:$$\\textrm{RMSE} =  \\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 }$$where \\( \\hat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 15\nFeature Imputation with a Heat Flux Dataset\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on thePredicting Critical Heat Fluxdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nFiles\ndata.csv- the competition dataset; your objective is to impute the missing values of thefeaturex_e_out [-](equilibrium quality)\nsample_submission.csv- a sample submission file in the correct format\nFiles\n2 files\nSize 1.73 MB\nType csv\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "imputation",
          "tabular",
          "feature engineering",
          "physics",
          "rmse"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e16",
      "description": "Challenge description:\nPlayground Series - Season 3, Episode 16: Regression with a Crab Age Dataset\n\nOverview\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nYour Goal: For this Episode of the Series, your task is to use regression to predict the age of crabs given physical attributes. Good luck!\nStart May 29, 2023\nClose June 12, 2023\n\nEvaluation\nSubmissions will be evaluated using Mean Absolute Error (MAE), where each x_i represents the predicted target, y_i represents the ground truth, and n is the number of rows in the test set.\n\nSubmission File\nFor each id in the test set, you must predict the target Age. The file should contain a header and have the following format:\nid,yield\n74051,10.2\n74051,3.6\n74051,11.9\netc.\n\nTimeline\nStart Date: May 30, 2023\nEntry Deadline: Same as the Final Submission Deadline\nTeam Merger Deadline: Same as the Final Submission Deadline\nFinal Submission Deadline: June 12, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes\n1st Place: Choice of Kaggle merchandise\n2nd Place: Choice of Kaggle merchandise\n3rd Place: Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Ashley Chow. Regression with a Crab Age Dataset. https://kaggle.com/competitions/playground-series-s3e16, 2023. Kaggle.\n\nCompetition Host\nKaggle\n\nPrizes & Awards\nSwag\nDoes not award Points or Medals\n\nParticipation\n3,807 Entrants\n1,467 Participants\n1,429 Teams\n10,531 Submissions\n\nTags\nBeginner, Tabular, Regression, Animals, Mean Absolute Error\n\nData description:\nPlayground Series - Season 3, Episode 16\nRegression with a Crab Age Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theCrab Age Predictiondataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nNote:You can usethis notebookto generate additional synthetic data for this competition if you would like.\n\nFiles\ntrain.csv- the training dataset;Ageis the target\ntest.csv- the test dataset; your objective is to predict the probability ofAge(the ground truth isintbut you can predictintorfloat)\nsample_submission.csv- a sample submission file in the correct format\n\nFiles: 3 files\nSize: 9.05 MB\nType: csv\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e16",
      "competition_description": "Challenge description:\nPlayground Series - Season 3, Episode 16: Regression with a Crab Age Dataset\n\nOverview\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nYour Goal: For this Episode of the Series, your task is to use regression to predict the age of crabs given physical attributes. Good luck!\nStart May 29, 2023\nClose June 12, 2023",
      "evaluation_metric": "Evaluation\nSubmissions will be evaluated using Mean Absolute Error (MAE), where each x_i represents the predicted target, y_i represents the ground truth, and n is the number of rows in the test set.",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 16\nRegression with a Crab Age Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theCrab Age Predictiondataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nNote:You can usethis notebookto generate additional synthetic data for this competition if you would like.\n\nFiles\ntrain.csv- the training dataset;Ageis the target\ntest.csv- the test dataset; your objective is to predict the probability ofAge(the ground truth isintbut you can predictintorfloat)\nsample_submission.csv- a sample submission file in the correct format\n\nFiles: 3 files\nSize: 9.05 MB\nType: csv\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "biology",
          "mae"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e19",
      "description": "Challenge description:\nForecasting Mini-Course Sales\nPlayground Series - Season 3, Episode 19\n\nDescription\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in July every Tuesday 00:00 UTC, with each competition running for 3 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nEvaluation\nSubmissions are evaluated on SMAPE between forecasts and actual values. We define SMAPE = 0 when the actual and predicted values are both 0.\n\nSubmission File\nFor each id in the test set, you must predict the corresponding num_sold. The file should contain a header and have the following format:\nid,num_sold\n136950,100\n136950,100\n136950,100\netc.\n\nTimeline\nStart Date: July 11, 2023\nEntry Deadline: Same as the Final Submission Deadline\nTeam Merger Deadline: Same as the Final Submission Deadline\nFinal Submission Deadline: July 31, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nPrizes\n1st Place: Choice of Kaggle merchandise\n2nd Place: Choice of Kaggle merchandise\n3rd Place: Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Ashley Chow. Forecasting Mini-Course Sales. https://kaggle.com/competitions/playground-series-s3e19, 2023. Kaggle.\n\nCompetition Host\nKaggle\n\nPrizes & Awards\nSwag\nDoes not award Points or Medals\n\nTags\nBeginner, Tabular, Time Series Analysis, SMAPE\n\nData description:\nPlayground Series - Season 3, Episode 19\nForecasting Mini-Course Sales\n\nDataset Description\nFor this challenge, you will be predicting a full year worth of sales for various fictitious learning modules from different fictitious Kaggle-branded stores in different (real!) countries. This dataset is completely synthetic, but contains many effects you see in real-world data, e.g., weekend and holiday effect, seasonality, etc. You are given the task of predicting sales during for year 2022.\n\nGood luck!\n\nFiles\ntrain.csv- the training set, which includes the sales data for each date-country-store-item combination.\ntest.csv- the test set; your task is to predict the corresponding item sales for each date-country-store-item combination. Note the Public leaderboard is scored on the first quarter of the test year, and the Private on the remaining.\nsample_submission.csv- a sample submission file in the correct format\n\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e19",
      "competition_description": "Challenge description:\nForecasting Mini-Course Sales\nPlayground Series - Season 3, Episode 19\n\nDescription\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in July every Tuesday 00:00 UTC, with each competition running for 3 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Evaluation\nSubmissions are evaluated on SMAPE between forecasts and actual values. We define SMAPE = 0 when the actual and predicted values are both 0.",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 19\nForecasting Mini-Course Sales\n\nDataset Description\nFor this challenge, you will be predicting a full year worth of sales for various fictitious learning modules from different fictitious Kaggle-branded stores in different (real!) countries. This dataset is completely synthetic, but contains many effects you see in real-world data, e.g., weekend and holiday effect, seasonality, etc. You are given the task of predicting sales during for year 2022.\n\nGood luck!\n\nFiles\ntrain.csv- the training set, which includes the sales data for each date-country-store-item combination.\ntest.csv- the test set; your task is to predict the corresponding item sales for each date-country-store-item combination. Note the Public leaderboard is scored on the first quarter of the test year, and the Private on the remaining.\nsample_submission.csv- a sample submission file in the correct format\n\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "time_series",
        "keywords": [
          "forecasting",
          "tabular_time_series",
          "lag_rolling_features",
          "retail_sales",
          "smape"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e21",
      "description": "Challenge description:\nPlayground Series - Season 3, Episode 21  \nImprove a Fixed Model the Data-Centric Way!  \n\nDescription  \nWelcome to the 2023 edition of Kaggle's Playground Series!  \nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!  \nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in August every Tuesday 00:00 UTC, with each competition running for 3 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!  \n\nEvaluation  \nThis is a different type of competition. Instead of submitting predictions, your task is to submit a dataset that will be used to train a random forest regressor model. This model will then be used to make predictions against a hidden test dataset. Your score will be the Root Mean Square Error (RMSE) between the model predictions and ground truth of the test set.  \n\nModel  \nYour submission will be used as a training dataset to train the following model and make predictions against a hidden test dataset.  \n```python  \nfrom sklearn.ensemble import RandomForestRegressor  \n\ny_train = train.pop('target')  # train is your submission!  \nrf = RandomForestRegressor(  \n       n_estimators=1000,  \n       max_depth=7,  \n       n_jobs=-1,  \n       random_state=42)  \nrf.fit(train, y_train)  \ny_hat = rf.predict(test)  # test set is hidden from you  \n```  \n\nSubmission File  \nYou are submitting a dataset that will be used to train a random forest model. Your submission must have all of the columns contained in the sample_submission.csv on the Data tab. Your submission must not contain any NaN values (it will error if it does). In addition, your submission may have fewer rows than the provided sample_submission.csv, but may not have a greater number of rows.  \n```  \nid,target,O2_1,O2_2,O2_3,...  \n0,8.59,7.5,9,9.545,...  \n1,9.1,13.533,40.9,8.77,...  \n2,8.21,3.71,5.42,8.77,...  \netc.  \n```  \n\nTimeline  \nStart Date - August 22, 2023  \nEntry Deadline - Same as the Final Submission Deadline  \nTeam Merger Deadline - Same as the Final Submission Deadline  \nFinal Submission Deadline - September 11, 2023  \nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.  \n\nPrizes  \n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.  \n\nCitation  \nWalter Reade, Sohier Dane, and Ashley Chow. Improve a Fixed Model the Data-Centric Way!. https://kaggle.com/competitions/playground-series-s3e21, 2023. Kaggle.  \n\nCompetition Host  \nKaggle  \n\nPrizes & Awards  \nSwag  \nDoes not award Points or Medals  \n\nParticipation  \n2,768 Entrants  \n986 Participants  \n955 Teams  \n10,344 Submissions  \n\nTags  \nBeginner  \nTabular  \nData Cleaning  \nCustom Metric\n\nData description:\nPlayground Series - Season 3, Episode 21\nImprove a Fixed Model the Data-Centric Way!\n\nThis is a very different type of challenge! For this challenge, your task is to improve a dataset that is being used to train a random forest model; in other words, your submission will be training data, not predictions. A random forest model will be trained on your submission, used to make predictions, and then those predictions will be used to generate your score.\nThe dataset for this competition is a synthetic dataset based off of the Dissolved oxygen prediction in river water dataset. You are free to use the original in any way that you find useful.\nPlease see important information on the Evaluation tab about the model that will be trained on your submitted data.\nGood luck!\nFiles\nsample_submission.csv - this is an example of the training data you will be submitting. Your submission must have all of the columns contained in this sample file. Your submission must not contain any NaN values (it will error if it does). In addition, your submission may have fewer rows than the provided sample_submission.csv, but may not have a greater number of rows.\nAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e21",
      "competition_description": "Challenge description:\nPlayground Series - Season 3, Episode 21  \nImprove a Fixed Model the Data-Centric Way!  \n\nDescription  \nWelcome to the 2023 edition of Kaggle's Playground Series!  \nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!  \nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in August every Tuesday 00:00 UTC, with each competition running for 3 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!  ",
      "evaluation_metric": "Evaluation  \nThis is a different type of competition. Instead of submitting predictions, your task is to submit a dataset that will be used to train a random forest regressor model. This model will then be used to make predictions against a hidden test dataset. Your score will be the Root Mean Square Error (RMSE) between the model predictions and ground truth of the test set.  ",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 21\nImprove a Fixed Model the Data-Centric Way!\n\nThis is a very different type of challenge! For this challenge, your task is to improve a dataset that is being used to train a random forest model; in other words, your submission will be training data, not predictions. A random forest model will be trained on your submission, used to make predictions, and then those predictions will be used to generate your score.\nThe dataset for this competition is a synthetic dataset based off of the Dissolved oxygen prediction in river water dataset. You are free to use the original in any way that you find useful.\nPlease see important information on the Evaluation tab about the model that will be trained on your submitted data.\nGood luck!\nFiles\nsample_submission.csv - this is an example of the training data you will be submitting. Your submission must have all of the columns contained in this sample file. Your submission must not contain any NaN values (it will error if it does). In addition, your submission may have fewer rows than the provided sample_submission.csv, but may not have a greater number of rows.\nAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature_engineering",
          "water_quality",
          "rmse"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e22",
      "description": "Challenge description:\nPlayground Series - Season 3, Episode 22\nPredict Health Outcomes of Horses\n\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in September every Tuesday 00:00 UTC, with each competition running for 3 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nYour Goal: Given various medical indicators, predict the health outcomes of horses.\nStart Sep 11, 2023 Close Oct 2, 2023\n\nDescription\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nEvaluation\nSubmissions are evaluated on micro-averaged F1-Score between pricted and actual values.\nSubmission File\nFor each id in the test set, you must predict the corresponding outcome. The file should contain a header and have the following format:\nid,outcome\n1235,lived\n1236,lived\n1237,died\n\nTimeline\nStart Date - September 12, 2023\nEntry Deadline - Same as the Final Submission Deadline\nTeam Merger Deadline - Same as the Final Submission Deadline\nFinal Submission Deadline - October 2, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Ashley Chow. Predict Health Outcomes of Horses. https://kaggle.com/competitions/playground-series-s3e22, 2023. Kaggle.\n\nCompetition Host\nKaggle\n\nPrizes & Awards\nSwag\nDoes not award Points or Medals\n\nParticipation\n4,907 Entrants\n1,628 Participants\n1,541 Teams\n12,287 Submissions\n\nTags\nBeginner\nTabular\nMulticlass Classification\nAnimals\nHealth\nF1 Score\n\nData description:\nPlayground Series - Season 3, Episode 22\nPredict Health Outcomes of Horses\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on a portion of theHorse Survival Dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nGood luck!\n\nFiles\ntrain.csv- the training dataset;outcomeis the (categorical) target\ntest.csv- the test dataset; your objective is to predictoutcome\nsample_submission.csv- a sample submission file in the correct format\n\nAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e22",
      "competition_description": "Challenge description:\nPlayground Series - Season 3, Episode 22\nPredict Health Outcomes of Horses\n\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nWith the same goal to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science, we will continue launching the Tabular Tuesday in September every Tuesday 00:00 UTC, with each competition running for 3 weeks. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nYour Goal: Given various medical indicators, predict the health outcomes of horses.\nStart Sep 11, 2023 Close Oct 2, 2023\n\nDescription\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Evaluation\nSubmissions are evaluated on micro-averaged F1-Score between pricted and actual values.",
      "dataset_description": "Playground Series - Season 3, Episode 22\nPredict Health Outcomes of Horses\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on a portion of theHorse Survival Dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nGood luck!\n\nFiles\ntrain.csv- the training dataset;outcomeis the (categorical) target\ntest.csv- the test dataset; your objective is to predictoutcome\nsample_submission.csv- a sample submission file in the correct format\n\nAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "multiclass classification",
          "tabular",
          "feature engineering",
          "animal_health",
          "f1-score"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e24",
      "description": "Challenge description:\nPlayground Series - Season 3, Episode 24: Binary Prediction of Smoker Status using Bio-Signals\n\nOverview\nWelcome to the 2023 Kaggle Playground Series!\nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nYour Goal: For this Episode of the Series, your task is to use binary classification to predict a patient's smoking status given information about various other health indicators. Good luck!\nStartOct 23, 2023CloseNov 13, 2023\n\nEvaluation\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n\nSubmission File\nFor each id in the test set, you must predict the probability for the target variable smoking. The file should contain a header and have the following format:\nid,smoking\n159256,0.5\n159257,0.5\n159258,0.5\netc.\n\nTimeline\nStart Date- October 24, 2023\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline- November 13, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\nDoes not award Points or Medals\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nCitation\nWalter Reade and Ashley Chow. Binary Prediction of Smoker Status using Bio-Signals. https://kaggle.com/competitions/playground-series-s3e24, 2023. Kaggle.\n\nCompetition Host\nKaggle\n\nData description:\nPlayground Series - Season 3, Episode 24\nBinary Prediction of Smoker Status using Bio-Signals\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Smoker Status Prediction using Bio-Signals dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; smoking is the binary target\ntest.csv - the test dataset; your objective is to predict the probability of positive smoking\nsample_submission.csv - a sample submission file in the correct format\n\nFiles: 3 files\nSize: 22.79 MB\nType: csv\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e24",
      "competition_description": "Challenge description:\nPlayground Series - Season 3, Episode 24: Binary Prediction of Smoker Status using Bio-Signals\n\nOverview\nWelcome to the 2023 Kaggle Playground Series!\nThank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nYour Goal: For this Episode of the Series, your task is to use binary classification to predict a patient's smoking status given information about various other health indicators. Good luck!\nStartOct 23, 2023CloseNov 13, 2023",
      "evaluation_metric": "Evaluation\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.",
      "dataset_description": "Dataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Smoker Status Prediction using Bio-Signals dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; smoking is the binary target\ntest.csv - the test dataset; your objective is to predict the probability of positive smoking\nsample_submission.csv - a sample submission file in the correct format\n\nFiles: 3 files\nSize: 22.79 MB\nType: csv\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "binary_classification",
          "tabular",
          "feature_engineering",
          "healthcare",
          "auc"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e25",
      "description": "Challenge description:\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!\n\nYour Goal: For this Episode of the Series, your task is to use regression to predict the Mohs hardness of a mineral, given its properties. Good luck!\n\nSubmissions are scored on the Median Absolute Error (MedAE). MedAE is defined as:\n$$\\textrm{MedAE}(y, \\widehat{y}) =  \\textrm{median}(|y_i - \\widehat{y}_i|, \\dots, |y_n - \\widehat{y}_n|)$$\nwhere \\( \\widehat{y}_i \\) is the predicted value and \\( y_i \\) is the ground truth for each observation \\(i\\).\n\nSubmission File\nFor each id row in the test set, you must predict the value for the target Hardness. The file should contain a header and have the following format:\nid,Hardness\n10407,4.647\n10408,4.647\n10409,4.647\netc.\n\nTimeline\nStart Date: November 14, 2023\nEntry Deadline: Same as the Final Submission Deadline\nTeam Merger Deadline: Same as the Final Submission Deadline\nFinal Submission Deadline: December 4, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Ashley Chow. Regression with a Mohs Hardness Dataset. https://kaggle.com/competitions/playground-series-s3e25, 2023. Kaggle.\n\nCompetition Host\nKaggle\n\nPrizes & Awards\nSwag\nDoes not award Points or Medals\n\nParticipation\n4,133 Entrants\n1,705 Participants\n1,632 Teams\n12,610 Submissions\n\nTags\nBeginner\nTabular\nRegression\nEarth Science\nMedian Absolute Error\n\nData description:\nPlayground Prediction Competition\n\nPlayground Series - Season 3, Episode 25\nRegression with a Mohs Hardness Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on thePrediction of Mohs Hardness with Machine Learningdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nFiles\ntrain.csv- the training dataset;Hardnessis the continuous target\ntest.csv- the test dataset; your objective is to predict the value ofHardness\nsample_submission.csv- a sample submission file in the correct format\nFiles3 filesSize2.11 MBTypecsvLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e25",
      "competition_description": "Challenge description:\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!\n\nYour Goal: For this Episode of the Series, your task is to use regression to predict the Mohs hardness of a mineral, given its properties. Good luck!",
      "evaluation_metric": "Submissions are scored on the Median Absolute Error (MedAE). MedAE is defined as:\n$$\\textrm{MedAE}(y, \\widehat{y}) =  \\textrm{median}(|y_i - \\widehat{y}_i|, \\dots, |y_n - \\widehat{y}_n|)$$\nwhere \\( \\widehat{y}_i \\) is the predicted value and \\( y_i \\) is the ground truth for each observation \\(i\\).",
      "dataset_description": "Data description:\nPlayground Prediction Competition\n\nPlayground Series - Season 3, Episode 25\nRegression with a Mohs Hardness Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on thePrediction of Mohs Hardness with Machine Learningdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nFiles\ntrain.csv- the training dataset;Hardnessis the continuous target\ntest.csv- the test dataset; your objective is to predict the value ofHardness\nsample_submission.csv- a sample submission file in the correct format\nFiles3 filesSize2.11 MBTypecsvLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "earth science",
          "medae"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e26",
      "description": "Challenge description:\n# Multi-Class Prediction of Cirrhosis Outcomes\n## Playground Series - Season 3, Episode 26\n\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far. This is our last episode for the Season 3 and we wish you all a Happy New Year! Stay tuned for the new season next year!\n\n## Your Goal\nFor this Episode of the Series, your task is to use a multi-class approach to predict the outcomes of patients with cirrhosis. Good luck!\n\n## Evaluation\nSubmissions are evaluated using the multi-class logarithmic loss. Each id in the test set had a single true class label, Status. For each id, you must submit a set of predicted probabilities for each of the three possible outcomes, e.g., Status_C, Status_CL, and Status_D.\n\nThe metric is calculated:\n$$log loss = -\\frac{1}{N}\\sum_{i=1}^N\\sum_{j=1}^My_{ij}\\log(p_{ij}),$$\nwhere $N$ is the number of rows in the test set, $M$ is the number of outcomes (i.e., 3), $log$ is the natural logarithm, $y_{ij}$ is 1 if row $i$ has the ground truth label $j$ and 0 otherwise, and $p_{ij}$ is the predicted probability that observation $i$ belongs to class $j$.\n\nThe submitted probabilities for a given row are not required to sum to one because they are rescaled prior to being scored (each row is divided by the row sum). In order to avoid the extremes of the log function, predicted probabilities are replaced with $max(min(p,1-10^{-15}),10^{-15})$.\n\n## Submission File\nFor each id row in the test set, you must predict probabilities of the three outcomes Status_C, Status_CL, and Status_D. The file should contain a header and have the following format:\n\nid,Status_C,Status_CL,Status_D\n7905,0.628084,0.034788,0.337128\n7906,0.628084,0.034788,0.337128\n7907,0.628084,0.034788,0.337128\netc.\n\n## Timeline\nStart Date: December 5, 2023  \nEntry Deadline: Same as the Final Submission Deadline  \nTeam Merger Deadline: Same as the Final Submission Deadline  \nFinal Submission Deadline: January 1, 2024  \n\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\n## About the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\n## Synthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\n## Prizes\n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \n\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\n## Citation\nWalter Reade and Ashley Chow. Multi-Class Prediction of Cirrhosis Outcomes. https://kaggle.com/competitions/playground-series-s3e26, 2023. Kaggle.\n\n## Competition Details\nCompetition Host: Kaggle  \nDoes not award Points or Medals  \n\n## Participation Statistics\n4,627 Entrants  \n1,718 Participants  \n1,661 Teams  \n15,115 Submissions  \n\n## Tags\nBeginner, Time Series Analysis, Tabular, Multiclass Classification, Log Loss\n\nData description:\nMulti-Class Prediction of Cirrhosis OutcomesPlayground Series - Season 3, Episode 26Dataset DescriptionThe dataset for this competition (both train and test) was generated from a deep learning model trained on theCirrhosis Patient Survival Predictiondataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.Filestrain.csv- the training dataset;Statusis the categorical target;C(censored) indicates the patient was alive atN_Days,CLindicates the patient was alive atN_Daysdue to liver a transplant, andDindicates the patient was deceased atN_Days.test.csv- the test dataset; your objective is to predict the probability of each of the threeStatusvalues, e.g.,Status_C,Status_CL,Status_D.sample_submission.csv- a sample submission file in the correct formatFiles3 filesSize1.39 MBTypecsvLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e26",
      "competition_description": "Challenge description:\n# Multi-Class Prediction of Cirrhosis Outcomes\n## Playground Series - Season 3, Episode 26\n\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far. This is our last episode for the Season 3 and we wish you all a Happy New Year! Stay tuned for the new season next year!\n\n## Your Goal\nFor this Episode of the Series, your task is to use a multi-class approach to predict the outcomes of patients with cirrhosis. Good luck!\n\n\n## About the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\n## Synthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "## Evaluation\nSubmissions are evaluated using the multi-class logarithmic loss. Each id in the test set had a single true class label, Status. For each id, you must submit a set of predicted probabilities for each of the three possible outcomes, e.g., Status_C, Status_CL, and Status_D.\n\nThe metric is calculated:\n$$log loss = -\\frac{1}{N}\\sum_{i=1}^N\\sum_{j=1}^My_{ij}\\log(p_{ij}),$$\nwhere $N$ is the number of rows in the test set, $M$ is the number of outcomes (i.e., 3), $log$ is the natural logarithm, $y_{ij}$ is 1 if row $i$ has the ground truth label $j$ and 0 otherwise, and $p_{ij}$ is the predicted probability that observation $i$ belongs to class $j$.\n\nThe submitted probabilities for a given row are not required to sum to one because they are rescaled prior to being scored (each row is divided by the row sum). In order to avoid the extremes of the log function, predicted probabilities are replaced with $max(min(p,1-10^{-15}),10^{-15})$.",
      "dataset_description": "Multi-Class Prediction of Cirrhosis OutcomesPlayground Series - Season 3, Episode 26Dataset DescriptionThe dataset for this competition (both train and test) was generated from a deep learning model trained on theCirrhosis Patient Survival Predictiondataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.Filestrain.csv- the training dataset;Statusis the categorical target;C(censored) indicates the patient was alive atN_Days,CLindicates the patient was alive atN_Daysdue to liver a transplant, andDindicates the patient was deceased atN_Days.test.csv- the test dataset; your objective is to predict the probability of each of the threeStatusvalues, e.g.,Status_C,Status_CL,Status_D.sample_submission.csv- a sample submission file in the correct formatFiles3 filesSize1.39 MBTypecsvLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "multiclass classification",
          "tabular",
          "feature engineering",
          "healthcare",
          "multiclass logloss"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e3",
      "description": "Challenge description:\nWelcome to the 2023 edition of Kaggle's Playground Series!  \nThank you to everyone who participated in and contributed to last year's Tabular Playground Series. And many thanks to all those who took the time to provide constructive feedback! We're thrilled that there continues to be interest in these types of challenges, and we're continuing the series this year but with a few changes.  \n\nFirst, the series is getting upgraded branding. We've dropped \"Tabular\" from the name because, while we anticipate this series will still have plenty of tabular competitions, we'll also be having some other formats as well. You'll also notice freshly-upgraded (better looking and more fun!) banner and thumbnail images.  \n\nSecond, rather than naming the challenges by month and year, we're moving to a Season-Edition format. This year is Season 3, and each challenge will be a new Edition. We're doing this to have more flexibility. Competitions going forward won't necessarily align with each month like they did in previous years (although some might!), we'll have competitions with different time durations, and we may have multiple competitions running at the same time on occasion.  \n\nRegardless of these changes, the goals of the Playground Series remain the same\u2014to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. We hope we continue to meet this objective!  \n\nTo start the year with some fun, January will be the month of Tabular Tuesday. We're launching four week-long tabular competitions, with each starting Tuesday 00:00 UTC. These will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!  \n\nEvaluation  \nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.  \n\nSubmission File  \nFor each EmployeeNumber in the test set, you must predict the probability for the target variable Attrition. The file should contain a header and have the following format:  \nEmployeeNumber,Attrition  \n1677,0.78  \n1678,0.34  \n1679,0.55  \netc.  \n\nTimeline  \nStart Date- January 17, 2023  \nEntry Deadline- Same as the Final Submission Deadline  \nTeam Merger Deadline- Same as the Final Submission Deadline  \nFinal Submission Deadline- January 23, 2023  \nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.  \n\nPrizes  \n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.  \n\nCitation  \nWalter Reade and Ashley Chow. Binary Classification with a Tabular Employee Attrition Dataset. https://kaggle.com/competitions/playground-series-s3e3, 2023. Kaggle.  \n\nCompetition Host Kaggle  \nPrizes & Awards Swag Does not award Points or Medals\n\nData description:\nPlayground Series - Season 3, Episode 3\nBinary Classification with a Tabular Employee Attrition Dataset\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on aEmployee Attrition. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nFiles\ntrain.csv- the training dataset;Attritionis the binary target\ntest.csv- the test dataset; your objective is to predict the probability of positiveAttrition\nsample_submission.csv- a sample submission file in the correct format\n3 files\nSize455.63 kB\nTypecsv\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e3",
      "competition_description": "Challenge description:\nWelcome to the 2023 edition of Kaggle's Playground Series!  \nThank you to everyone who participated in and contributed to last year's Tabular Playground Series. And many thanks to all those who took the time to provide constructive feedback! We're thrilled that there continues to be interest in these types of challenges, and we're continuing the series this year but with a few changes.  \n\nFirst, the series is getting upgraded branding. We've dropped \"Tabular\" from the name because, while we anticipate this series will still have plenty of tabular competitions, we'll also be having some other formats as well. You'll also notice freshly-upgraded (better looking and more fun!) banner and thumbnail images.  \n\nSecond, rather than naming the challenges by month and year, we're moving to a Season-Edition format. This year is Season 3, and each challenge will be a new Edition. We're doing this to have more flexibility. Competitions going forward won't necessarily align with each month like they did in previous years (although some might!), we'll have competitions with different time durations, and we may have multiple competitions running at the same time on occasion.  \n\nRegardless of these changes, the goals of the Playground Series remain the same\u2014to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. We hope we continue to meet this objective!  \n\nTo start the year with some fun, January will be the month of Tabular Tuesday. We're launching four week-long tabular competitions, with each starting Tuesday 00:00 UTC. These will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Evaluation  \nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 3\nBinary Classification with a Tabular Employee Attrition Dataset\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on aEmployee Attrition. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nFiles\ntrain.csv- the training dataset;Attritionis the binary target\ntest.csv- the test dataset; your objective is to predict the probability of positiveAttrition\nsample_submission.csv- a sample submission file in the correct format\n3 files\nSize455.63 kB\nTypecsv\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "binary classification",
          "tabular",
          "feature engineering",
          "hr/employee attrition",
          "auc"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e5",
      "description": "Challenge description:\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nYour Goal: For this Episode of the Series, your task is to use regression to predict the quality of wine based on various properties. Good luck!\n\nSubmissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement). In the event that there is less agreement than expected by chance, the metric may go below 0.\nThe quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that O_{i,j} corresponds to the number of Ids i (actual) that received a predicted value j. An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted values:\n$$w_{i,j} = \\frac{(i-j)^2}{(N-1)^2}$$\nAn N-by-N histogram matrix of expected outcomes, E, is calculated assuming that there is no correlation between values. This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and O have the same sum.\nFrom these three matrices, the quadratic weighted kappa is calculated as:\n$$\\kappa = 1 - \\frac{\\sum_{i,j} w_{i,j} O_{i,j}}{\\sum_{i,j} w_{i,j} E_{i,j}}.$$\n\nFor each Id in the test set, you must predict the value for the target quality. The file should contain a header and have the following format:\nId,quality\n2056,5\n2057,7\n2058,3\netc.\n\nTimeline:\nStart Date- January 31, 2023\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline- February 13, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series:\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets:\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes:\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation:\nWalter Reade and Ashley Chow. Ordinal Regression with a Tabular Wine Quality Dataset. https://kaggle.com/competitions/playground-series-s3e5, 2023. Kaggle.\n\nCompetition Host: Kaggle\nPrizes & Awards: Swag\nDoes not award Points or Medals\nParticipation: 2,131 Entrants, 933 Participants, 901 Teams, 8,644 Submissions\nTags: Beginner, Tabular, Cohen Kappa Score\n\nData description:\nPlayground Series - Season 3, Episode 5\nOrdinal Regression with a Tabular Wine Quality Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theWine Quality dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nFilestrain.csv- the training dataset;qualityis the target (ordinal, integer)\ntest.csv- the test dataset; your objective is to predictquality\nsample_submission.csv- a sample submission file in the correct format\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e5",
      "competition_description": "Challenge description:\nWelcome to the 2023 Kaggle Playground Series! Thank you to everyone who participated in and contributed to Season 3 Playground Series so far!\nYour Goal: For this Episode of the Series, your task is to use regression to predict the quality of wine based on various properties. Good luck!\n\nTimeline:\nStart Date- January 31, 2023\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline- February 13, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series:\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets:\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes:\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation:\nWalter Reade and Ashley Chow. Ordinal Regression with a Tabular Wine Quality Dataset. https://kaggle.com/competitions/playground-series-s3e5, 2023. Kaggle.\n\nCompetition Host: Kaggle\nPrizes & Awards: Swag\nDoes not award Points or Medals\nParticipation: 2,131 Entrants, 933 Participants, 901 Teams, 8,644 Submissions\nTags: Beginner, Tabular, Cohen Kappa Score",
      "evaluation_metric": "Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two outcomes. This metric typically varies from 0 (random agreement) to 1 (complete agreement). In the event that there is less agreement than expected by chance, the metric may go below 0.\nThe quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that O_{i,j} corresponds to the number of Ids i (actual) that received a predicted value j. An N-by-N matrix of weights, w, is calculated based on the difference between actual and predicted values:\n$$w_{i,j} = \\frac{(i-j)^2}{(N-1)^2}$$\nAn N-by-N histogram matrix of expected outcomes, E, is calculated assuming that there is no correlation between values. This is calculated as the outer product between the actual histogram vector of outcomes and the predicted histogram vector, normalized such that E and O have the same sum.\nFrom these three matrices, the quadratic weighted kappa is calculated as:\n$$\\kappa = 1 - \\frac{\\sum_{i,j} w_{i,j} O_{i,j}}{\\sum_{i,j} w_{i,j} E_{i,j}}.$$",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 5\nOrdinal Regression with a Tabular Wine Quality Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theWine Quality dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nFilestrain.csv- the training dataset;qualityis the target (ordinal, integer)\ntest.csv- the test dataset; your objective is to predictquality\nsample_submission.csv- a sample submission file in the correct format\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature_engineering",
          "food_beverage",
          "quadratic_weighted_kappa"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e7",
      "description": "Challenge description:\nPlayground Series - Season 3, Episode 7  \nBinary Classification with a Tabular Reservation Cancellation Dataset  \n\nWelcome to the 2023 edition of Kaggle's Playground Series!  \nThank you to everyone who participated in and contributed to last year's Tabular Playground Series. And many thanks to all those who took the time to provide constructive feedback! We're thrilled that there continues to be interest in these types of challenges, and we're continuing the series this year but with a few changes.  \n\nFirst, the series is getting upgraded branding. We've dropped \"Tabular\" from the name because, while we anticipate this series will still have plenty of tabular competitions, we'll also be having some other formats as well. You'll also notice freshly-upgraded (better looking and more fun!) banner and thumbnail images.  \n\nSecond, rather than naming the challenges by month and year, we're moving to a Season-Edition format. This year is Season 3, and each challenge will be a new Edition. We're doing this to have more flexibility. Competitions going forward won't necessarily align with each month like they did in previous years (although some might!), we'll have competitions with different time durations, and we may have multiple competitions running at the same time on occasion.  \n\nRegardless of these changes, the goals of the Playground Series remain the same\u2014to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. We hope we continue to meet this objective!  \n\nWith the great start and participation in January, we will continue launching the Tabular Tuesday in February every Tuesday 00:00 UTC, with each competition running for 2 weeks instead. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!  \n\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.  \n\nFor each id in the test set, you must predict the value for the target booking_status. The file should contain a header and have the following format:  \nid,booking_status  \n42100,0  \n42101,1  \n42102,0  \netc.  \n\nStart Date - February 14, 2023  \nEntry Deadline - Same as the Final Submission Deadline  \nTeam Merger Deadline - Same as the Final Submission Deadline  \nFinal Submission Deadline - February 27, 2023  \nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.  \n\n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.  \n\nWalter Reade and Ashley Chow. Binary Classification with a Tabular Reservation Cancellation Dataset. https://kaggle.com/competitions/playground-series-s3e7, 2023. Kaggle.  \n\nCompetition Host Kaggle  \nDoes not award Points or Medals\n\nData description:\nPlayground Series - Season 3, Episode 7\nBinary Classification with a Tabular Reservation Cancellation Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theReservation Cancellation Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv- the training dataset;booking_statusis the target (e.g., whether the reservation was cancelled)\ntest.csv- the test dataset; your objective is to predictbooking_status\nsample_submission.csv- a sample submission file in the correct format\n\nMetadata\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e7",
      "competition_description": "Challenge description:\nPlayground Series - Season 3, Episode 7  \nBinary Classification with a Tabular Reservation Cancellation Dataset  \n\nWelcome to the 2023 edition of Kaggle's Playground Series!  \nThank you to everyone who participated in and contributed to last year's Tabular Playground Series. And many thanks to all those who took the time to provide constructive feedback! We're thrilled that there continues to be interest in these types of challenges, and we're continuing the series this year but with a few changes.  \n\nFirst, the series is getting upgraded branding. We've dropped \"Tabular\" from the name because, while we anticipate this series will still have plenty of tabular competitions, we'll also be having some other formats as well. You'll also notice freshly-upgraded (better looking and more fun!) banner and thumbnail images.  \n\nSecond, rather than naming the challenges by month and year, we're moving to a Season-Edition format. This year is Season 3, and each challenge will be a new Edition. We're doing this to have more flexibility. Competitions going forward won't necessarily align with each month like they did in previous years (although some might!), we'll have competitions with different time durations, and we may have multiple competitions running at the same time on occasion.  \n\nRegardless of these changes, the goals of the Playground Series remain the same\u2014to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. We hope we continue to meet this objective!  \n\nWith the great start and participation in January, we will continue launching the Tabular Tuesday in February every Tuesday 00:00 UTC, with each competition running for 2 weeks instead. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.",
      "dataset_description": "Data description:\nPlayground Series - Season 3, Episode 7\nBinary Classification with a Tabular Reservation Cancellation Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theReservation Cancellation Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv- the training dataset;booking_statusis the target (e.g., whether the reservation was cancelled)\ntest.csv- the test dataset; your objective is to predictbooking_status\nsample_submission.csv- a sample submission file in the correct format\n\nMetadata\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "binary classification",
          "tabular",
          "feature engineering",
          "hospitality",
          "auc"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s3e9",
      "description": "Challenge description:\nPlayground Series - Season 3, Episode 9\nRegression with a Tabular Concrete Strength Dataset\n\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to last year's Tabular Playground Series. And many thanks to all those who took the time to provide constructive feedback! We're thrilled that there continues to be interest in these types of challenges, and we're continuing the series this year but with a few changes.\n\nFirst, the series is getting upgraded branding. We've dropped \"Tabular\" from the name because, while we anticipate this series will still have plenty of tabular competitions, we'll also be having some other formats as well. You'll also notice freshly-upgraded (better looking and more fun!) banner and thumbnail images.\n\nSecond, rather than naming the challenges by month and year, we're moving to a Season-Edition format. This year is Season 3, and each challenge will be a new Edition. We're doing this to have more flexibility. Competitions going forward won't necessarily align with each month like they did in previous years (although some might!), we'll have competitions with different time durations, and we may have multiple competitions running at the same time on occasion.\n\nRegardless of these changes, the goals of the Playground Series remain the same\u2014to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. We hope we continue to meet this objective!\n\nWith the great start and participation in January, we will continue launching the Tabular Tuesday in February every Tuesday 00:00 UTC, with each competition running for 2 weeks instead. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nEvaluation\nRoot Mean Squared Error (RMSE)\nSubmissions are scored on the root mean squared error. RMSE is defined as:\n$$\\textrm{RMSE} =  \\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 }$$\nwhere \\( \\hat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).\n\nSubmission File\nFor each id in the test set, you must predict the value for the target Strength. The file should contain a header and have the following format:\nid,Strength\n5439,55.2\n5440,12.3\n5441,83.4\netc.\n\nTimeline\nStart Date- February 28, 2023\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline-  March 13, 2023\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\nDoes not award Points or Medals\n\nCitation\nWalter Reade and Ashley Chow. Regression with a Tabular Concrete Strength Dataset. https://kaggle.com/competitions/playground-series-s3e9, 2023. Kaggle.\n\nCompetition Host\nKaggle\n\nData description:\nRegression with a Tabular Concrete Strength Dataset\nPlayground Series - Season 3, Episode 9\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theConcrete Strength Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv- the training dataset;Strengthis the target\ntest.csv- the test dataset; your objective is to predictStrength\nsample_submission.csv- a sample submission file in the correct format\n\nFiles3 filesSize485.23 kBTypecsvLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s3e9",
      "competition_description": "Challenge description:\nPlayground Series - Season 3, Episode 9\nRegression with a Tabular Concrete Strength Dataset\n\nWelcome to the 2023 edition of Kaggle's Playground Series!\nThank you to everyone who participated in and contributed to last year's Tabular Playground Series. And many thanks to all those who took the time to provide constructive feedback! We're thrilled that there continues to be interest in these types of challenges, and we're continuing the series this year but with a few changes.\n\nFirst, the series is getting upgraded branding. We've dropped \"Tabular\" from the name because, while we anticipate this series will still have plenty of tabular competitions, we'll also be having some other formats as well. You'll also notice freshly-upgraded (better looking and more fun!) banner and thumbnail images.\n\nSecond, rather than naming the challenges by month and year, we're moving to a Season-Edition format. This year is Season 3, and each challenge will be a new Edition. We're doing this to have more flexibility. Competitions going forward won't necessarily align with each month like they did in previous years (although some might!), we'll have competitions with different time durations, and we may have multiple competitions running at the same time on occasion.\n\nRegardless of these changes, the goals of the Playground Series remain the same\u2014to give the Kaggle community a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. We hope we continue to meet this objective!\n\nWith the great start and participation in January, we will continue launching the Tabular Tuesday in February every Tuesday 00:00 UTC, with each competition running for 2 weeks instead. Again, these will be fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Evaluation\nRoot Mean Squared Error (RMSE)\nSubmissions are scored on the root mean squared error. RMSE is defined as:\n$$\\textrm{RMSE} =  \\sqrt{ \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2 }$$\nwhere \\( \\hat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).",
      "dataset_description": "Data description:\nRegression with a Tabular Concrete Strength Dataset\nPlayground Series - Season 3, Episode 9\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theConcrete Strength Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv- the training dataset;Strengthis the target\ntest.csv- the test dataset; your objective is to predictStrength\nsample_submission.csv- a sample submission file in the correct format\n\nFiles3 filesSize485.23 kBTypecsvLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "materials science",
          "rmse"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e1",
      "description": "Challenge description:\nPlayground Series - Season 4, Episode 1\nBinary Classification with a Bank Churn Dataset\n\nWelcome to the 2024 Kaggle Playground Series! Happy New Year! This is the 1st episode of Season 4. We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: For this Episode of the Series, your task is to predict whether a customer continues with their account or closes it (e.g., churns). Good luck!\n\nStart Jan 1, 2024\nClose Jan 31, 2024\n\nEvaluation\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n\nSubmission File\nFor each id in the test set, you must predict the probability for the target variable Exited. The file should contain a header and have the following format:\nid,Exited\n165034,0.9\n165035,0.1\n165036,0.5\netc.\n\nTimeline\nStart Date - January 2, 2024\nEntry Deadline - Same as the Final Submission Deadline\nTeam Merger Deadline - Same as the Final Submission Deadline\nFinal Submission Deadline - January 31, 2024\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Ashley Chow. Binary Classification with a Bank Churn Dataset. https://kaggle.com/competitions/playground-series-s4e1, 2024. Kaggle.\n\nCompetition Host\nKaggle\n\nPrizes & Awards\nSwag\nDoes not award Points or Medals\n\nParticipation\n8,898 Entrants\n3,777 Participants\n3,632 Teams\n28,457 Submissions\n\nTags\nBeginner\nTabular\nBinary Classification\nBanking\nRoc Auc Score\n\nData description:\nPlayground Series - Season 4, Episode 1\nBinary Classification with a Bank Churn Dataset\nPlayground Prediction Competition 2 years ago Late Submission\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Bank Customer Churn Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Exited is the binary target\ntest.csv - the test dataset; your objective is to predict the probability of Exited\nsample_submission.csv - a sample submission file in the correct format\n\nLicense Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s4e1",
      "competition_description": "Challenge description:\nPlayground Series - Season 4, Episode 1\nBinary Classification with a Bank Churn Dataset\n\nWelcome to the 2024 Kaggle Playground Series! Happy New Year! This is the 1st episode of Season 4. We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: For this Episode of the Series, your task is to predict whether a customer continues with their account or closes it (e.g., churns). Good luck!\n\nStart Jan 1, 2024\nClose Jan 31, 2024",
      "evaluation_metric": "Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.",
      "dataset_description": "Dataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Bank Customer Churn Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Exited is the binary target\ntest.csv - the test dataset; your objective is to predict the probability of Exited\nsample_submission.csv - a sample submission file in the correct format\n\nLicense Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "classification",
          "tabular",
          "feature engineering",
          "banking",
          "roc-auc"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e10",
      "description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nThe goal for this competition is to predict whether an applicant is approved for a loan.\n\nEvaluation:\nSubmissions are evaluated using area under the ROC curve using the predicted probabilities and the ground truth targets.\n\nSubmission File:\nFor each id row in the test set, you must predict target loan_status. The file should contain a header and have the following format:\nid,loan_status\n58645,0.5\n58646,0.5\n58647,0.5\netc.\n\nTimeline:\nStart Date - October 1, 2024\nEntry Deadline - Same as the Final Submission Deadline\nTeam Merger Deadline - Same as the Final Submission Deadline\nFinal Submission Deadline - October 31, 2024\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series:\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets:\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes:\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nDoes not award Points or Medals.\n\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation:\nWalter Reade and Ashley Chow. Loan Approval Prediction. https://kaggle.com/competitions/playground-series-s4e10, 2024. Kaggle.\n\nData description:\nPlayground Series - Season 4, Episode 10\nLoan Approval Prediction\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Loan Approval Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; loan_status is the binary target\ntest.csv - the test dataset; your objective is to predict probability of the target loan_status for each row\nsample_submission.csv - a sample submission file in the correct format\n\nLicense\nAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s4e10",
      "competition_description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nThe goal for this competition is to predict whether an applicant is approved for a loan.\n\nAbout the Tabular Playground Series:\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets:\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Evaluation:\nSubmissions are evaluated using area under the ROC curve using the predicted probabilities and the ground truth targets.",
      "dataset_description": "Data description:\nPlayground Series - Season 4, Episode 10\nLoan Approval Prediction\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Loan Approval Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; loan_status is the binary target\ntest.csv - the test dataset; your objective is to predict probability of the target loan_status for each row\nsample_submission.csv - a sample submission file in the correct format\n\nLicense\nAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "classification",
          "tabular",
          "feature engineering",
          "finance",
          "auc"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e11",
      "description": "Challenge description:\nPlayground Series - Season 4, Episode 11: Exploring Mental Health Data\n\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: Your goal is to use data from a mental health survey to explore factors that may cause individuals to experience depression.\n\nEvaluation\nSubmissions are evaluated using Accuracy Score.\nFor each id row in the test set, you must predict the target Depression. The file should contain a header and have the following format:\nid,Depression\n140700,0\n140701,0\n140702,1\netc.\n\nTimeline\nStart Date - November 1, 2024\nEntry Deadline - Same as the Final Submission Deadline\nTeam Merger Deadline - Same as the Final Submission Deadline\nFinal Submission Deadline - November 30, 2024\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Elizabeth Park. Exploring Mental Health Data. https://kaggle.com/competitions/playground-series-s4e11, 2024. Kaggle.\n\nCompetition Host: Kaggle\n\nDoes not award Points or Medals\n\nParticipation\n7,954 Entrants\n2,891 Participants\n2,685 Teams\n23,174 Submissions\n\nTags\nBeginner\nTime Series Analysis\nTabular\nAccuracy Score\n\nData description:\nPlayground Series - Season 4, Episode 11\nExploring Mental Health Data\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theDepression Survey/Dataset for Analysisdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nNotes:\nA number of data artifacts have been left in the synthetic dataset.\nThis is not a particularly difficult dataset to model. It may be interesting to focus on different ways to visualize the dataset.\nFiles\ntrain.csv- the training dataset;classis the binary target (eithereorp)\ntest.csv- the test dataset; your objective is to predict targetclassfor each row\nsample_submission.csv- a sample submission file in the correct format\nMetadata\nLicense\nCC0: Public Domain",
      "docker_challenge_path": "/data/playground-series-s4e11",
      "competition_description": "Challenge description:\nPlayground Series - Season 4, Episode 11: Exploring Mental Health Data\n\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: Your goal is to use data from a mental health survey to explore factors that may cause individuals to experience depression.",
      "evaluation_metric": "Submissions are evaluated using Accuracy Score.",
      "dataset_description": "Playground Series - Season 4, Episode 11\nExploring Mental Health Data\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theDepression Survey/Dataset for Analysisdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nNotes:\nA number of data artifacts have been left in the synthetic dataset.\nThis is not a particularly difficult dataset to model. It may be interesting to focus on different ways to visualize the dataset.\nFiles\ntrain.csv- the training dataset;classis the binary target (eithereorp)\ntest.csv- the test dataset; your objective is to predict targetclassfor each row\nsample_submission.csv- a sample submission file in the correct format\nMetadata\nLicense\nCC0: Public Domain",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "classification",
          "tabular",
          "feature engineering",
          "healthcare",
          "accuracy"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e12",
      "description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: The objectives of this challenge is to predict insurance premiums based on various factors.\n\nStart Nov 30, 2024  \nClose Dec 31, 2024\n\nEvaluation  \nSubmissions are evaluated using the Root Mean Squared Logarithmic Error (RMSLE).\n\nSubmission File  \nFor each id row in the test set, you must predict the continuous target Premium Amount. The file should contain a header and have the following format:  \nid,Premium Amount  \n1200000,1102.545  \n1200001,1102.545  \n1200002,1102.545  \netc.\n\nTimeline  \nStart Date - December 1, 2024  \nEntry Deadline - Same as the Final Submission Deadline  \nTeam Merger Deadline - Same as the Final Submission Deadline  \nFinal Submission Deadline - December 31, 2024  \nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series  \nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes  \n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation  \nWalter Reade and Elizabeth Park. Regression with an Insurance Dataset. https://kaggle.com/competitions/playground-series-s4e12, 2024. Kaggle.\n\nCompetition Host  \nKaggle\n\nPrizes & Awards  \nSwag  \nDoes not award Points or Medals\n\nParticipation  \n7,737 Entrants  \n2,512 Participants  \n2,390 Teams  \n17,851 Submissions\n\nTags  \nBeginner  \nTabular  \nInsurance  \nRegression  \nRoot Mean Squared Logarithmic Error\n\nData description:\nPlayground Series - Season 4, Episode 12\nRegression with an Insurance Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Insurance Premium Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Premium Amount is the continuous target\ntest.csv - the test dataset; your objective is to predict target Premium Amount for each row\nsample_submission.csv - a sample submission file in the correct format\n\nFiles: 3 files\nSize: 332.74 MB\nType: csv\nLicense: Apache 2.0",
      "docker_challenge_path": "/data/playground-series-s4e12",
      "competition_description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: The objectives of this challenge is to predict insurance premiums based on various factors.\n\nStart Nov 30, 2024  \nClose Dec 31, 2024",
      "evaluation_metric": "Evaluation  \nSubmissions are evaluated using the Root Mean Squared Logarithmic Error (RMSLE).",
      "dataset_description": "Playground Series - Season 4, Episode 12\nRegression with an Insurance Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Insurance Premium Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Premium Amount is the continuous target\ntest.csv - the test dataset; your objective is to predict target Premium Amount for each row\nsample_submission.csv - a sample submission file in the correct format\n\nFiles: 3 files\nSize: 332.74 MB\nType: csv\nLicense: Apache 2.0",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "insurance",
          "rmsle"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e2",
      "description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.  \nYour Goal: The goal of this competition is to use various factors to predict obesity risk in individuals, which is related to cardiovascular disease. Good luck!  \nStart Jan 31, 2024  \nClose Feb 29, 2024  \n\nSubmissions are evaluated using the accuracy score.  \nSubmission File: For each id row in the test set, you must predict the class value of the target, NObeyesdad. The file should contain a header and have the following format:  \nid,NObeyesdad  \n20758,Normal_Weight  \n20759,Normal_Weight  \n20760,Normal_Weight  \netc.  \n\nTimeline:  \nStart Date - February 1, 2024  \nEntry Deadline - Same as the Final Submission Deadline  \nTeam Merger Deadline - Same as the Final Submission Deadline  \nFinal Submission Deadline - February 29, 2024  \nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.  \n\nAbout the Tabular Playground Series:  \nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets:  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!  \n\nPrizes:  \n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.  \n\nCitation:  \nWalter Reade and Ashley Chow. Multi-Class Prediction of Obesity Risk. https://kaggle.com/competitions/playground-series-s4e2, 2024. Kaggle.\n\nData description:\nMulti-Class Prediction of Obesity RiskPlayground Series - Season 4, Episode 2\nDataset DescriptionThe dataset for this competition (both train and test) was generated from a deep learning model trained on theObesity or CVD riskdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.Note:This dataset is particularly well suited for visualizations, clustering, and general EDA. Show off your skills!Filestrain.csv- the training dataset;NObeyesdadis the categorical targettest.csv- the test dataset; your objective is to predict the class ofNObeyesdadfor each rowsample_submission.csv- a sample submission file in the correct formatMetadataLicenseCC BY-SA 4.0",
      "docker_challenge_path": "/data/playground-series-s4e2",
      "competition_description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.  \nYour Goal: The goal of this competition is to use various factors to predict obesity risk in individuals, which is related to cardiovascular disease. Good luck!  \nStart Jan 31, 2024  \nClose Feb 29, 2024",
      "evaluation_metric": "Submissions are evaluated using the accuracy score.",
      "dataset_description": "Data description:\nMulti-Class Prediction of Obesity RiskPlayground Series - Season 4, Episode 2\nDataset DescriptionThe dataset for this competition (both train and test) was generated from a deep learning model trained on theObesity or CVD riskdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.Note:This dataset is particularly well suited for visualizations, clustering, and general EDA. Show off your skills!Filestrain.csv- the training dataset;NObeyesdadis the categorical targettest.csv- the test dataset; your objective is to predict the class ofNObeyesdadfor each rowsample_submission.csv- a sample submission file in the correct formatMetadataLicenseCC BY-SA 4.0",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "multiclass classification",
          "tabular",
          "feature engineering",
          "healthcare",
          "accuracy"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e3",
      "description": "Challenge description:\nPlayground Series - Season 4, Episode 3\nSteel Plate Defect Prediction\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\nYour Goal: Predict the probability of various defects on steel plates. Good luck!\nStartFeb 29, 2024CloseMar 31, 2024\nSubmissions are evaluated using area under the ROC curve using the predicted probabilities and the ground truth targets.\nTo calculate the final score, AUC is calculated for each of the 7 defect categories and then averaged. In other words, the score is the average of the individual AUC of each predicted column.\nFor each id in the test set, you must predict the probability for each of 7 defect categories: Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, Other_Faults. The file should contain a header and have the following format:\nid,Pastry,Z_Scratch,K_Scatch,Stains,Dirtiness,Bumps,Other_Faults\n19219,0.5,0.5,0.5,0.5,0.5,0.5,0.5\n19220,0.5,0.5,0.5,0.5,0.5,0.5,0.5\n19221,0.5,0.5,0.5,0.5,0.5,0.5,0.5\netc.\nStart Date- March 1, 2024\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline-  March 31, 2024\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\nWalter Reade and Ashley Chow. Steel Plate Defect Prediction. https://kaggle.com/competitions/playground-series-s4e3, 2024. Kaggle.\nCompetition HostKaggle\nPrizes & AwardsSwagDoes not award Points or Medals\nParticipation6,473 Entrants2,303 Participants2,199 Teams17,300 Submissions\nTagsBeginnerTabularMulticlass ClassificationBinary ClassificationManufacturingMean Columnwise Area Under Receiver Operating Characteristic Curve\n\nData description:\nPlayground Series - Season 4, Episode 3: Steel Plate Defect Prediction\n\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Steel Plates Faults dataset from UCI. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; there are 7 binary targets: Pastry,Z_Scratch,K_Scatch,Stains,Dirtiness,Bumps,Other_Faults\ntest.csv - the test dataset; your objective is to predict the probability of each of the 7 binary targets\nsample_submission.csv - a sample submission file in the correct format\n\nMetadata\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s4e3",
      "competition_description": "Challenge description:\nPlayground Series - Season 4, Episode 3\nSteel Plate Defect Prediction\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\nYour Goal: Predict the probability of various defects on steel plates. Good luck!\nStartFeb 29, 2024CloseMar 31, 2024\n\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Submissions are evaluated using area under the ROC curve using the predicted probabilities and the ground truth targets.\nTo calculate the final score, AUC is calculated for each of the 7 defect categories and then averaged. In other words, the score is the average of the individual AUC of each predicted column.",
      "dataset_description": "Data description:\nPlayground Series - Season 4, Episode 3: Steel Plate Defect Prediction\n\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Steel Plates Faults dataset from UCI. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; there are 7 binary targets: Pastry,Z_Scratch,K_Scatch,Stains,Dirtiness,Bumps,Other_Faults\ntest.csv - the test dataset; your objective is to predict the probability of each of the 7 binary targets\nsample_submission.csv - a sample submission file in the correct format\n\nMetadata\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "multilabel classification",
          "tabular",
          "feature engineering",
          "manufacturing",
          "auc-roc"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e4",
      "description": "Challenge description:\nPlayground Series - Season 4, Episode 4\nRegression with an Abalone Dataset\n\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nThe goal of this competition is to predict the age of abalone from various physical measurements.\n\nStart Mar 31, 2024\nClose Apr 30, 2024\n\nEvaluation:\nThe evaluation metric for this competition is Root Mean Squared Logarithmic Error.\nThe RMSLE is calculated as:\n$$\\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left(\\log (1 + \\hat{y}_i) - \\log (1 + y_i)\\right)^2}$$\nwhere:\n\\(n\\) is the total number of observations in the test set,\n\\(\\hat{y}_i\\) is the predicted value of the target for instance (i),\n\\(y_i\\) is the actual value of the target for instance (i), and,\n\\(\\log\\) is the natural logarithm.\n\nSubmission File:\nFor each id row in the test set, you must predict the target, Rings. The file should contain a header and have the following format:\nid,Rings\n90615,10\n90616,10\n90617,10\netc.\n\nTimeline:\nStart Date - April 1, 2024\nEntry Deadline - Same as the Final Submission Deadline\nTeam Merger Deadline - Same as the Final Submission Deadline\nFinal Submission Deadline - April 30, 2024\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series:\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets:\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes:\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation:\nWalter Reade and Ashley Chow. Regression with an Abalone Dataset. https://kaggle.com/competitions/playground-series-s4e4, 2024. Kaggle.\n\nCompetition Host: Kaggle\n\nPrizes & Awards:\nSwag\nDoes not award Points or Medals\n\nParticipation:\n5,859 Entrants\n2,719 Participants\n2,606 Teams\n21,531 Submissions\n\nTags:\nBeginner, Tabular, Regression, Mean Squared Log Error\n\nData description:\nPlayground Series - Season 4, Episode 4\nRegression with an Abalone Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theAbalonedataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv- the training dataset;Ringsis the integer target\ntest.csv- the test dataset; your objective is to predict the value ofRingsfor each row\nsample_submission.csv- a sample submission file in the correct format\n\nLicense Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s4e4",
      "competition_description": "Challenge description:\nPlayground Series - Season 4, Episode 4\nRegression with an Abalone Dataset\n\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nThe goal of this competition is to predict the age of abalone from various physical measurements.\n\nStart Mar 31, 2024\nClose Apr 30, 2024",
      "evaluation_metric": "Evaluation:\nThe evaluation metric for this competition is Root Mean Squared Logarithmic Error.\nThe RMSLE is calculated as:\n$$\\sqrt{ \\frac{1}{n} \\sum_{i=1}^n \\left(\\log (1 + \\hat{y}_i) - \\log (1 + y_i)\\right)^2}$$\nwhere:\n\\(n\\) is the total number of observations in the test set,\n\\(\\hat{y}_i\\) is the predicted value of the target for instance (i),\n\\(y_i\\) is the actual value of the target for instance (i), and,\n\\(\\log\\) is the natural logarithm.",
      "dataset_description": "Data description:\nPlayground Series - Season 4, Episode 4\nRegression with an Abalone Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theAbalonedataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv- the training dataset;Ringsis the integer target\ntest.csv- the test dataset; your objective is to predict the value ofRingsfor each row\nsample_submission.csv- a sample submission file in the correct format\n\nLicense Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "marine biology",
          "rmsle"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e5",
      "description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series!We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.Your Goal:The goal of this competition is to predict the probability of a region flooding based on various factors.StartApr 30, 2024CloseMay 31, 2024EvaluationSubmissions are evaluated using theR2 score.Submission FileFor eachidrow in the test set, you must predict the value of the target,FloodProbability. The file should contain a header and have the following format:id,FloodProbability1117957,0.51117958,0.51117959,0.5etc.Timelinelinkkeyboard_arrow_upStart Date- May 1, 2024Entry Deadline- Same as the Final Submission DeadlineTeam Merger Deadline- Same as the Final Submission DeadlineFinal Submission Deadline-  May 31, 2024All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.About the Tabular Playground SeriesThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.Synthetically-Generated DatasetsUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!Prizes1st Place - Choice of Kaggle merchandise2nd Place - Choice of Kaggle merchandise3rd Place - Choice of Kaggle merchandisePlease note:In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.CitationWalter Reade and Ashley Chow. Regression with a Flood Prediction Dataset. https://kaggle.com/competitions/playground-series-s4e5, 2024. Kaggle.CiteCompetition HostKagglePrizes & AwardsSwagDoes not award Points or MedalsParticipation7,193 Entrants2,932 Participants2,788 Teams21,519 SubmissionsTagsBeginnerTabularLogistic RegressionR2 ScoreTable of Contentscollapse_allOverviewEvaluationTimelineAbout the Tabular Playground SeriesPrizesCitation\n\nData description:\nPlayground Series - Season 4, Episode 5\nRegression with a Flood Prediction Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theFlood Prediction Factorsdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nNote:This dataset is particularly well suited for visualizations, clustering, and general EDA. Show off your skills!\n\nFiles\ntrain.csv- the training dataset;FloodProbabilityis the target\ntest.csv- the test dataset; your objective is to predict theFloodProbabilityfor each row\nsample_submission.csv- a sample submission file in the correct format\n\nMetadata\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s4e5",
      "competition_description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series!We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.Your Goal:The goal of this competition is to predict the probability of a region flooding based on various factors.StartApr 30, 2024CloseMay 31, 2024Submission FileFor eachidrow in the test set, you must predict the value of the target,FloodProbability. The file should contain a header and have the following format:id,FloodProbability1117957,0.51117958,0.51117959,0.5etc.Timelinelinkkeyboard_arrow_upStart Date- May 1, 2024Entry Deadline- Same as the Final Submission DeadlineTeam Merger Deadline- Same as the Final Submission DeadlineFinal Submission Deadline-  May 31, 2024All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.About the Tabular Playground SeriesThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.Synthetically-Generated DatasetsUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!Prizes1st Place - Choice of Kaggle merchandise2nd Place - Choice of Kaggle merchandise3rd Place - Choice of Kaggle merchandisePlease note:In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.CitationWalter Reade and Ashley Chow. Regression with a Flood Prediction Dataset. https://kaggle.com/competitions/playground-series-s4e5, 2024. Kaggle.CiteCompetition HostKagglePrizes & AwardsSwagDoes not award Points or MedalsParticipation7,193 Entrants2,932 Participants2,788 Teams21,519 SubmissionsTagsBeginnerTabularLogistic RegressionR2 ScoreTable of Contentscollapse_allOverviewEvaluationTimelineAbout the Tabular Playground SeriesPrizesCitation",
      "evaluation_metric": "Submissions are evaluated using theR2 score.",
      "dataset_description": "Playground Series - Season 4, Episode 5\nRegression with a Flood Prediction Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on theFlood Prediction Factorsdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nNote:This dataset is particularly well suited for visualizations, clustering, and general EDA. Show off your skills!\n\nFiles\ntrain.csv- the training dataset;FloodProbabilityis the target\ntest.csv- the test dataset; your objective is to predict theFloodProbabilityfor each rowsample_submission.csv- a sample submission file in the correct format\n\nMetadata\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "geospatial",
          "r2_score"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e6",
      "description": "Challenge description:\nPlayground Series - Season 4, Episode 6\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\nYour Goal: The goal of this competition is to predict academic risk of students in higher education.\nSubmissions are evaluated using the accuracy score.\nFor each id row in the test set, you must predict the class value of the Target, which is a categorical academic risk assessment. The file should contain a header and have the following format:\nid,Target\n76518,Graduate\n76519,Graduate\n76520,Graduate\netc.\nStart Date- June 1, 2024\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline- June 30, 2024\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\nWalter Reade and Ashley Chow. Classification with an Academic Success Dataset. https://kaggle.com/competitions/playground-series-s4e6, 2024. Kaggle.\nCompetition Host\nKaggle\nPrizes & Awards\nSwag\nDoes not award Points or Medals\nParticipation\n7,152 Entrants\n2,858 Participants\n2,684 Teams\n20,893 Submissions\nTags\nBeginner\nTabular\nEducation\nAccuracy Score\n\nData description:\nPlayground Series - Season 4, Episode 6\nClassification with an Academic Success Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on thePredict Students' Dropout and Academic Successdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance. Please refer to the original dataset for feature feature explanations.\n\nFiles\ntrain.csv- the training dataset;Targetis the categorical target\ntest.csv- the test dataset; your objective is to predict the class ofTargetfor each row\nsample_submission.csv- a sample submission file in the correct format\n\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s4e6",
      "competition_description": "Challenge description:\nPlayground Series - Season 4, Episode 6\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\nYour Goal: The goal of this competition is to predict academic risk of students in higher education.\nSubmissions are evaluated using the accuracy score.\nFor each id row in the test set, you must predict the class value of the Target, which is a categorical academic risk assessment. The file should contain a header and have the following format:\nid,Target\n76518,Graduate\n76519,Graduate\n76520,Graduate\netc.\nStart Date- June 1, 2024\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline- June 30, 2024\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Submissions are evaluated using the accuracy score.",
      "dataset_description": "Data description:\nPlayground Series - Season 4, Episode 6\nClassification with an Academic Success Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on thePredict Students' Dropout and Academic Successdataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance. Please refer to the original dataset for feature feature explanations.\n\nFiles\ntrain.csv- the training dataset;Targetis the categorical target\ntest.csv- the test dataset; your objective is to predict the class ofTargetfor each row\nsample_submission.csv- a sample submission file in the correct format\n\nLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "classification",
          "tabular",
          "feature_engineering",
          "education",
          "accuracy"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e7",
      "description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nThe objective of this competition is to predict which customers respond positively to an automobile insurance offer.\n\nStart Jun 30, 2024\nClose Jul 31, 2024\n\nEvaluation\nSubmissions are evaluated using area under the ROC curve using the predicted probabilities and the ground truth targets.\n\nSubmission File\nFor each id row in the test set, you must predict the probability of the target, Response. The file should contain a header and have the following format:\nid,Response\n11504798,0.5\n11504799,0.5\n11504800,0.5\netc.\n\nTimeline\nStart Date - July 1, 2024\nEntry Deadline - Same as the Final Submission Deadline\nTeam Merger Deadline - Same as the Final Submission Deadline\nFinal Submission Deadline - July 31, 2024\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Ashley Chow. Binary Classification of Insurance Cross Selling . https://kaggle.com/competitions/playground-series-s4e7, 2024. Kaggle.\n\nCompetition Host\nKaggle\n\nDoes not award Points or Medals\n\nParticipation\n6,545 Entrants\n2,425 Participants\n2,234 Teams\n15,844 Submissions\n\nTags\nBeginner\nTabular\nBinary Classification\nRoc Auc Score\n\nData description:\nPlayground Series - Season 4, Episode 7\nBinary Classification of Insurance Cross Selling\nDataset DescriptionThe dataset for this competition (both train and test) was generated from a deep learning model trained on theHealth Insurance Cross Sell Prediction Datadataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.Thisnotebookgives more details about the dataset used for this competition.Filestrain.csv- the training dataset;Responseis the binary targettest.csv- the test dataset; your objective is to predict the probability ofResponsefor each rowsample_submission.csv- a sample submission file in the correct formattext_snippetMetadataLicenseAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s4e7",
      "competition_description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nThe objective of this competition is to predict which customers respond positively to an automobile insurance offer.\n\nStart Jun 30, 2024\nClose Jul 31, 2024",
      "evaluation_metric": "Evaluation\nSubmissions are evaluated using area under the ROC curve using the predicted probabilities and the ground truth targets.",
      "dataset_description": "Data description:\nPlayground Series - Season 4, Episode 7\nBinary Classification of Insurance Cross Selling\nDataset DescriptionThe dataset for this competition (both train and test) was generated from a deep learning model trained on theHealth Insurance Cross Sell Prediction Datadataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.Thisnotebookgives more details about the dataset used for this competition.Filestrain.csv- the training dataset;Responseis the binary targettest.csv- the test dataset; your objective is to predict the probability ofResponsefor each rowsample_submission.csv- a sample submission file in the correct formattext_snippetMetadataLicenseAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "binary_classification",
          "tabular",
          "feature_engineering",
          "insurance",
          "auc"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e8",
      "description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nThe goal of this competition is to predict whether a mushroom is edible or poisonous based on its physical characteristics.\n\nStart: July 31, 2024\nClose: August 31, 2024\n\nEvaluation:\nSubmissions are evaluated using the Matthews correlation coefficient (MCC).\n\nSubmission File:\nFor each id row in the test set, you must predict target class, whether the observation is editable (e) or poisonous (p). The file should contain a header and have the following format:\nid,class\n3116945,e\n3116946,p\n3116947,e\netc.\n\nTimeline:\nStart Date: August 1, 2024\nEntry Deadline: Same as the Final Submission Deadline\nTeam Merger Deadline: Same as the Final Submission Deadline\nFinal Submission Deadline: August 31, 2024\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series:\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets:\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes:\n1st Place: Choice of Kaggle merchandise\n2nd Place: Choice of Kaggle merchandise\n3rd Place: Choice of Kaggle merchandise\n\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation:\nWalter Reade and Ashley Chow. Binary Prediction of Poisonous Mushrooms. https://kaggle.com/competitions/playground-series-s4e8, 2024. Kaggle.\n\nCompetition Host: Kaggle\n\nPrizes & Awards: Swag\nDoes not award Points or Medals\n\nTags: Beginner, Time Series Analysis, Tabular, Matthews Corrcoef\n\nData description:\nPlayground Series - Season 4, Episode 8\nBinary Prediction of Poisonous Mushrooms\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the UCI Mushroom dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nNote: Unlike many previous Tabular Playground datasets, data artifacts have not been cleaned up. There are categorical values in the dataset that are not found in the original. It is up to the competitors how to handle this.\n\nFiles\ntrain.csv - the training dataset; class is the binary target (either e or p)\ntest.csv - the test dataset; your objective is to predict target class for each row\nsample_submission.csv - a sample submission file in the correct format\n\nMetadata\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s4e8",
      "competition_description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nThe goal of this competition is to predict whether a mushroom is edible or poisonous based on its physical characteristics.\n\nStart: July 31, 2024\nClose: August 31, 2024",
      "evaluation_metric": "Evaluation:\nSubmissions are evaluated using the Matthews correlation coefficient (MCC).",
      "dataset_description": "Data description:\nPlayground Series - Season 4, Episode 8\nBinary Prediction of Poisonous Mushrooms\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the UCI Mushroom dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\nNote: Unlike many previous Tabular Playground datasets, data artifacts have not been cleaned up. There are categorical values in the dataset that are not found in the original. It is up to the competitors how to handle this.\n\nFiles\ntrain.csv - the training dataset; class is the binary target (either e or p)\ntest.csv - the test dataset; your objective is to predict target class for each row\nsample_submission.csv - a sample submission file in the correct format\n\nMetadata\nLicense: Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "binary classification",
          "tabular",
          "feature engineering",
          "biology",
          "mcc"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s4e9",
      "description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: The goal of this competition is to predict the price of used cars based on various attributes.\n\nEvaluation:  \nRoot Mean Squared Error (RMSE)  \nSubmissions are scored on the root mean squared error. RMSE is defined as:  \n$$\\textrm{RMSE} =  \\left( \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\widehat{y}_i)^2 \\right)^{\\frac{1}{2}}$$  \nwhere \\( \\widehat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).\n\nSubmission File:  \nFor each id in the test set, you must predict the price of the car. The file should contain a header and have the following format:  \nid,price  \n188533,43878.016  \n188534,43878.016  \n188535,43878.016  \netc.\n\nTimeline:  \nStart Date - September 1, 2024  \nEntry Deadline - Same as the Final Submission Deadline  \nTeam Merger Deadline - Same as the Final Submission Deadline  \nFinal Submission Deadline - September 30, 2024  \nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series:  \nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets:  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes:  \n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation:  \nWalter Reade and Ashley Chow. Regression of Used Car Prices. https://kaggle.com/competitions/playground-series-s4e9, 2024. Kaggle.\n\nCompetition Host: Kaggle  \nPrizes & Awards: Swag  \nDoes not award Points or Medals  \nTags: Beginner, Time Series Analysis, Tabular, Mean Squared Error\n\nData description:\nPlayground Series - Season 4, Episode 9\nRegression of Used Car Prices\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Used Car Price Prediction Dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; price is the continuous target\ntest.csv - the test dataset; your objective is to predict the value of price for each row\nsample_submission.csv - a sample submission file in the correct format\n\nLicense\nAttribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s4e9",
      "competition_description": "Challenge description:\nWelcome to the 2024 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: The goal of this competition is to predict the price of used cars based on various attributes.",
      "evaluation_metric": "Evaluation:  \nRoot Mean Squared Error (RMSE)  \nSubmissions are scored on the root mean squared error. RMSE is defined as:  \n$$\\textrm{RMSE} =  \\left( \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\widehat{y}_i)^2 \\right)^{\\frac{1}{2}}$$  \nwhere \\( \\widehat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).",
      "dataset_description": "Data description:\nPlayground Series - Season 4, Episode 9\nRegression of Used Car Prices\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Used Car Price Prediction Dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; price is the continuous target\ntest.csv - the test dataset; your objective is to predict the value of price for each row\nsample_submission.csv - a sample submission file in the correct format\n\nLicense\nAttribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "automotive",
          "rmse"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s5e1",
      "description": "Challenge description:\nForecasting Sticker Sales\nPlayground Series - Season 5, Episode 1\n\nOverview\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: The objective of this challenge is to forecast sticker sales in different countries. \"At Kaggle, we take stickers seriously!\"\u2122\ufe0f\n\nStart Dec 31, 2024\nClose Jan 31, 2025\n\nEvaluation\nSubmissions are evaluated using the Mean Absolute Percentage Error (MAPE).\n\nSubmission File\nFor each id row in the test set, you must predict the target num_sold. The file should contain a header and have the following format:\nid,num_sold\n230130,100\n230131,100\n230132,100\netc.\n\nTimeline\nStart Date: January 1, 2025\nEntry Deadline: Same as the Final Submission Deadline\nTeam Merger Deadline: Same as the Final Submission Deadline\nFinal Submission Deadline: January 31, 2025\n\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes\n1st Place: Choice of Kaggle merchandise\n2nd Place: Choice of Kaggle merchandise\n3rd Place: Choice of Kaggle merchandise\n\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Elizabeth Park. Forecasting Sticker Sales. https://kaggle.com/competitions/playground-series-s5e1, 2025. Kaggle.\n\nCompetition Host\nKaggle\n\nPrizes & Awards\nSwag\nDoes not award Points or Medals\n\nParticipation\n7,622 Entrants\n2,811 Participants\n2,722 Teams\n22,758 Submissions\n\nTags\nBeginner, Tabular, Time Series Analysis, Mean Absolute Percentage Error\n\nData description:\nPlayground Series - Season 5, Episode 1\nForecasting Sticker Sales\nKaggle\u00b7 Playground Prediction Competition \u00b77 months agoLate Submission\nDataset Description\nMetadata\nLicense Attribution 4.0 International (CC BY 4.0)",
      "docker_challenge_path": "/data/playground-series-s5e1",
      "competition_description": "Challenge description:\nForecasting Sticker Sales\nPlayground Series - Season 5, Episode 1\n\nOverview\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: The objective of this challenge is to forecast sticker sales in different countries. \"At Kaggle, we take stickers seriously!\"\u2122\ufe0f\n\nStart Dec 31, 2024\nClose Jan 31, 2025",
      "evaluation_metric": "Evaluation\nSubmissions are evaluated using the Mean Absolute Percentage Error (MAPE).",
      "dataset_description": "Data description:\nPlayground Series - Season 5, Episode 1\nForecasting Sticker Sales\nKaggle\u00b7 Playground Prediction Competition \u00b77 months agoLate Submission\nDataset Description\nMetadata\nLicense Attribution 4.0 International (CC BY 4.0)",
      "metadata": {
        "domain": "time_series",
        "keywords": [
          "forecasting",
          "tabular_time_series",
          "feature engineering",
          "retail sales",
          "mape"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s5e2",
      "description": "Challenge description:\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: Predict the price of backpacks given various attributes.\n\nStart: January 31, 2025  \nClose: February 28, 2025  \n\nEvaluation  \nRoot Mean Squared Error (RMSE)  \nSubmissions are scored on the root mean squared error. RMSE is defined as:  \n$$\\textrm{RMSE} =  \\left( \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\widehat{y}_i)^2 \\right)^{\\frac{1}{2}}$$  \nwhere \\( \\widehat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).  \n\nSubmission File  \nFor each id in the test set, you must predict the Price of the backpack. The file should contain a header and have the following format:  \nid,Price  \n300000,81.411  \n300001,81.411  \n300002,81.411  \netc.  \n\nTimeline  \nStart Date: February 1, 2025  \nEntry Deadline: Same as the Final Submission Deadline  \nTeam Merger Deadline: Same as the Final Submission Deadline  \nFinal Submission Deadline: February 28, 2025  \n\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.  \n\nAbout the Tabular Playground Series  \nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!  \n\nPrizes  \n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \n\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.  \n\nCitation  \nWalter Reade and Elizabeth Park. Backpack Prediction Challenge. https://kaggle.com/competitions/playground-series-s5e2, 2025. Kaggle.  \n\nCompetition Host  \nKaggle  \n\nPrizes & Awards  \nSwag  \nDoes not award Points or Medals  \n\nParticipation  \n8,597 Entrants  \n3,566 Participants  \n3,393 Teams  \n23,588 Submissions  \n\nTags  \nBeginner  \nTabular  \nMean Squared Error\n\nData description:\nBackpack Prediction Challenge\nPlayground Series - Season 5, Episode 2\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Student Bag Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Price is the target\ntrain_extra.csv - a lot more training data!\ntest.csv - the test dataset; your objective is to predict the probability of Price for each row\nsample_submission.csv - a sample submission file in the correct format.\n\nMetadata\nLicense MIT",
      "docker_challenge_path": "/data/playground-series-s5e2",
      "competition_description": "Challenge description:\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: Predict the price of backpacks given various attributes.\n\nStart: January 31, 2025  \nClose: February 28, 2025  \n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Evaluation  \nRoot Mean Squared Error (RMSE)  \nSubmissions are scored on the root mean squared error. RMSE is defined as:  \n$$\\textrm{RMSE} =  \\left( \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\widehat{y}_i)^2 \\right)^{\\frac{1}{2}}$$  \nwhere \\( \\widehat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).",
      "dataset_description": "Backpack Prediction Challenge\nPlayground Series - Season 5, Episode 2\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Student Bag Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Price is the target\ntrain_extra.csv - a lot more training data!\ntest.csv - the test dataset; your objective is to predict the probability of Price for each row\nsample_submission.csv - a sample submission file in the correct format.\n\nMetadata\nLicense MIT",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "gradient boosting",
          "rmse"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s5e3",
      "description": "Challenge description:\nPlayground Series - Season 5, Episode 3\n\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: Your goal is to predict rainfall for each day of the year.\n\nSubmissions are evaluated on area under the ROC curve between the predicted probability and the observed target.\n\nFor each id in the test set, you must predict a probability for the target rainfall. The file should contain a header and have the following format: id,rainfall2190,0.52191,0.12192,0.9etc.\n\nStart Date- March 1, 2025\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline- March 31, 2025\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Elizabeth Park. Binary Prediction with a Rainfall Dataset. https://kaggle.com/competitions/playground-series-s5e3, 2025. Kaggle.\n\nData description:\nPlayground Series - Season 5, Episode 3\nBinary Prediction with a Rainfall Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Rainfall Prediction using Machine Learning dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv- the training dataset; rainfall is the binary target\ntest.csv- the test dataset; your objective is to predict the probability of rainfall for each row\nsample_submission.csv- a sample submission file in the correct format.\n\nMetadata\nLicense MIT",
      "docker_challenge_path": "/data/playground-series-s5e3",
      "competition_description": "Challenge description:\nPlayground Series - Season 5, Episode 3\n\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: Your goal is to predict rainfall for each day of the year.\n\nStart Date- March 1, 2025\nEntry Deadline- Same as the Final Submission Deadline\nTeam Merger Deadline- Same as the Final Submission Deadline\nFinal Submission Deadline- March 31, 2025\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!",
      "evaluation_metric": "Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target.",
      "dataset_description": "Data description:\nPlayground Series - Season 5, Episode 3\nBinary Prediction with a Rainfall Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Rainfall Prediction using Machine Learning dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv- the training dataset; rainfall is the binary target\ntest.csv- the test dataset; your objective is to predict the probability of rainfall for each row\nsample_submission.csv- a sample submission file in the correct format.\n\nMetadata\nLicense MIT",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "binary classification",
          "tabular",
          "feature engineering",
          "meteorology",
          "auc"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s5e4",
      "description": "Challenge description:\nPlayground Series - Season 5, Episode 4\n\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nYour task is to predict listening time of a podcast episode.\n\nStart: Mar 31, 2025\nClose: Apr 30, 2025\n\nEvaluation:\nRoot Mean Squared Error (RMSE)\nSubmissions are scored on the root mean squared error. RMSE is defined as:\n$$\\textrm{RMSE} =  \\left( \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\widehat{y}_i)^2 \\right)^{\\frac{1}{2}}$$\nwhere \\( \\widehat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).\n\nSubmission File:\nFor each id in the test set, you must predict the Listening_Time_minutes of the podcast. The file should contain a header and have the following format:\nid,Listening_Time_minutes\n750000,45.437\n750001,45.437\n750002,45.437\netc.\n\nTimeline:\nStart Date: April 1, 2025\nEntry Deadline: Same as the Final Submission Deadline\nTeam Merger Deadline: Same as the Final Submission Deadline\nFinal Submission Deadline: April 30, 2025\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series:\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets:\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nCitation:\nWalter Reade and Elizabeth Park. Predict Podcast Listening Time. https://kaggle.com/competitions/playground-series-s5e4, 2025. Kaggle.\n\nCompetition Host:\nKaggle\n\nPrizes & Awards:\nSwag\nDoes not award Points or Medals\n\nParticipation:\n8,639 Entrants\n3,454 Participants\n3,310 Teams\n26,079 Submissions\n\nTags:\nBeginner\nTabular\nMean Squared Error\n\nData description:\nPlayground Series - Season 5, Episode 4: Predict Podcast Listening Time\n\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Podcast Listening Time Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Listening_Time_minutes is the target\ntest.csv - the test dataset; your objective is to predict the Listening_Time_minutes for each row\nsample_submission.csv - a sample submission file in the correct format.\n\nLicense\nApache 2.0",
      "docker_challenge_path": "/data/playground-series-s5e4",
      "competition_description": "Challenge description:\nPlayground Series - Season 5, Episode 4\n\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal:\nYour task is to predict listening time of a podcast episode.\n\nStart: Mar 31, 2025\nClose: Apr 30, 2025",
      "evaluation_metric": "Evaluation:\nRoot Mean Squared Error (RMSE)\nSubmissions are scored on the root mean squared error. RMSE is defined as:\n$$\\textrm{RMSE} =  \\left( \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\widehat{y}_i)^2 \\right)^{\\frac{1}{2}}$$\nwhere \\( \\widehat{y}_i \\) is the predicted value and \\( y_i \\) is the original value for each instance \\(i\\).",
      "dataset_description": "Data description:\nPlayground Series - Season 5, Episode 4: Predict Podcast Listening Time\n\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Podcast Listening Time Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Listening_Time_minutes is the target\ntest.csv - the test dataset; your objective is to predict the Listening_Time_minutes for each row\nsample_submission.csv - a sample submission file in the correct format.\n\nLicense\nApache 2.0",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature_engineering",
          "entertainment",
          "rmse"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s5e5",
      "description": "Challenge description:\nPlayground Series - Season 5, Episode 5\nPredict Calorie Expenditure\n\nOverview\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: Your goal is to predict how many calories were burned during a workout.\n\nStart Apr 30, 2025\nClose May 31, 2025\n\nEvaluation\nThe evaluation metric for this competition is Root Mean Squared Logarithmic Error.\n\nThe RMSLE is calculated as:\n$$\\textrm{RMSLE} =   \\left( \\frac{1}{n} \\sum_{i=1}^n \\left(\\log (1 + \\widehat{y}_i) - \\log (1 + y_i)\\right) \\right)^{\\frac{1}{2}}$$\n\nwhere:\n\\(n\\) is the total number of observations in the test set,\n\\(\\widehat{y}_i\\) is the predicted value of the target for instance (i),\n\\(y_i\\) is the actual value of the target for instance (i), and,\n\\(\\log\\) is the natural logarithm.\n\nSubmission File\nFor each id row in the test set, you must predict the continuous target, Calories. The file should contain a header and have the following format:\nid,Calories\n750000,93.2\n750001,27.42\n750002,103.8\netc.\n\nTimeline\nStart Date - May 1, 2025\nEntry Deadline - Same as the Final Submission Deadline\nTeam Merger Deadline - Same as the Final Submission Deadline\nFinal Submission Deadline - May 31, 2025\n\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\n\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\n\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\n\nCitation\nWalter Reade and Elizabeth Park. Predict Calorie Expenditure. https://kaggle.com/competitions/playground-series-s5e5, 2025. Kaggle.\n\nCompetition Host\nKaggle\n\nPrizes & Awards\nSwag\nDoes not award Points or Medals\n\nParticipation\n9,345 Entrants\n4,486 Participants\n4,316 Teams\n37,192 Submissions\n\nTags\nBeginner Tabular Mean Squared Log Error\n\nData description:\nPlayground Series - Season 5, Episode 5\nPredict Calorie Expenditure\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Calories Burnt Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Calories is the continuous target\ntest.csv - the test dataset; your objective is to predict the Calories for each row\nsample_submission.csv - a sample submission file in the correct format.\n\nLicense\nApache 2.0",
      "docker_challenge_path": "/data/playground-series-s5e5",
      "competition_description": "Challenge description:\nPlayground Series - Season 5, Episode 5\nPredict Calorie Expenditure\n\nOverview\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\n\nYour Goal: Your goal is to predict how many calories were burned during a workout.\n\nStart Apr 30, 2025\nClose May 31, 2025",
      "evaluation_metric": "Evaluation\nThe evaluation metric for this competition is Root Mean Squared Logarithmic Error.\n\nThe RMSLE is calculated as:\n$$\\textrm{RMSLE} =   \\left( \\frac{1}{n} \\sum_{i=1}^n \\left(\\log (1 + \\widehat{y}_i) - \\log (1 + y_i)\\right) \\right)^{\\frac{1}{2}}$$\n\nwhere:\n\\(n\\) is the total number of observations in the test set,\n\\(\\widehat{y}_i\\) is the predicted value of the target for instance (i),\n\\(y_i\\) is the actual value of the target for instance (i), and,\n\\(\\log\\) is the natural logarithm.",
      "dataset_description": "Data description:\nPlayground Series - Season 5, Episode 5\nPredict Calorie Expenditure\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Calories Burnt Prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Calories is the continuous target\ntest.csv - the test dataset; your objective is to predict the Calories for each row\nsample_submission.csv - a sample submission file in the correct format.\n\nLicense\nApache 2.0",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "regression",
          "tabular",
          "feature engineering",
          "healthcare",
          "rmsle"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s5e6",
      "description": "Challenge description:\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.  \nYour Goal:  \nYour objective is to select the best fertilizer for different weather, soil conditions and crops.  \nStart May 31, 2025  \nClose Jun 30, 2025  \n\nEvaluation  \nSubmissions are evaluated according to the Mean Average Precision @ 3 (MAP@3):  \n$$MAP@5 = \\frac{1}{U} \\sum_{u=1}^{U} \\sum_{k=1}^{min(n,5)} P(k) \\times rel(k)$$  \nwhere \\( U \\) is the number of observations, \\( P(k) \\) is the precision at cutoff \\( k \\), \\( n \\) is the number predictions per observation, and \\( rel(k) \\) is an indicator function equaling 1 if the item at rank \\( k \\) is a relevant (correct) label, zero otherwise.  \nOnce a correct label has been scored for an observation, that label is no longer considered relevant for that observation, and additional predictions of that label are skipped in the calculation. For example, if the correct label is A for an observation, the following predictions all score an average precision of 1.0.  \n[A, B, C, D, E]  \n[A, A, A, A, A]  \n[A, B, A, C, A]  \n\nSubmission File  \nFor each id in the test set, you may predict up to 3 Fertilizer Name values, with the predictions space delimited. The file should contain a header and have the following format:  \nid,Fertilizer Name  \n750000,14-35-14 10-26-26 Urea  \n750000,14-35-14 10-26-26 Urea  \n...  \n\nTimeline  \nStart Date - June 1, 2025  \nEntry Deadline - Same as the Final Submission Deadline  \nTeam Merger Deadline - Same as the Final Submission Deadline  \nFinal Submission Deadline - June 30, 2025  \nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.  \n\nAbout the Tabular Playground Series  \nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.  \n\nSynthetically-Generated Datasets  \nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!  \n\nPrizes  \n1st Place - Choice of Kaggle merchandise  \n2nd Place - Choice of Kaggle merchandise  \n3rd Place - Choice of Kaggle merchandise  \nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.  \n\nCitation  \nWalter Reade and Elizabeth Park. Predicting Optimal Fertilizers. https://kaggle.com/competitions/playground-series-s5e6, 2025. Kaggle.  \n\nCompetition Host  \nKaggle  \n\nPrizes & Awards  \nSwag  \nDoes not award Points or Medals  \n\nParticipation  \n7,070 Entrants  \n2,779 Participants  \n2,648 Teams  \n19,969 Submissions  \n\nTags  \nBeginner  \nTabular  \nMAP@{K}\n\nData description:\nPlayground Series - Season 5, Episode 6\nPredicting Optimal Fertilizers\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Fertilizer prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Fertilizer Name is the categorical target\ntest.csv - the test dataset; your objective is to predict the Fertilizer Name for each row, up to three value, space delimited.\nsample_submission.csv - a sample submission file in the correct format.\n\nMetadata\nLicense CC0: Public Domain",
      "docker_challenge_path": "/data/playground-series-s5e6",
      "competition_description": "Challenge description:\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.  \nYour Goal:  \nYour objective is to select the best fertilizer for different weather, soil conditions and crops.  \nStart May 31, 2025  \nClose Jun 30, 2025",
      "evaluation_metric": "Evaluation  \nSubmissions are evaluated according to the Mean Average Precision @ 3 (MAP@3):  \n$$MAP@5 = \\frac{1}{U} \\sum_{u=1}^{U} \\sum_{k=1}^{min(n,5)} P(k) \\times rel(k)$$  \nwhere \\( U \\) is the number of observations, \\( P(k) \\) is the precision at cutoff \\( k \\), \\( n \\) is the number predictions per observation, and \\( rel(k) \\) is an indicator function equaling 1 if the item at rank \\( k \\) is a relevant (correct) label, zero otherwise.  \nOnce a correct label has been scored for an observation, that label is no longer considered relevant for that observation, and additional predictions of that label are skipped in the calculation. For example, if the correct label is A for an observation, the following predictions all score an average precision of 1.0.  \n[A, B, C, D, E]  \n[A, A, A, A, A]  \n[A, B, A, C, A]",
      "dataset_description": "Playground Series - Season 5, Episode 6\nPredicting Optimal Fertilizers\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Fertilizer prediction dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; Fertilizer Name is the categorical target\ntest.csv - the test dataset; your objective is to predict the Fertilizer Name for each row, up to three value, space delimited.\nsample_submission.csv - a sample submission file in the correct format.\n\nMetadata\nLicense CC0: Public Domain",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "classification",
          "tabular",
          "feature engineering",
          "agriculture",
          "map"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s5e7",
      "description": "Challenge description:\nCleaned description:\nOverviewWelcome to the 2025 Kaggle Playground Series!We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.Your Goal:Your objective is to predict whether a person is an Introvert or Extrovert, given their social behavior and personality traits.StartJun 30, 2025CloseJul 31, 2025EvaluationSubmissions are evaluated usingAccuracy Scorebetween the predicted value and the observed target.Submission FileFor eachidin the test set, you must predict the targetPersonality. The file should contain a header and have the following format:id,Personality18524,Extrovert18525,Introvert18526,Introvertetc.TimelinelinkStart Date- June 30, 2025Entry Deadline- Same as the Final Submission DeadlineTeam Merger Deadline- Same as the Final Submission DeadlineFinal Submission Deadline-  July 31, 2025All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.About the Tabular Playground SeriesThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.Synthetically-Generated DatasetsUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!Prizes1st Place - Choice of Kaggle merchandise2nd Place - Choice of Kaggle merchandise3rd Place - Choice of Kaggle merchandisePlease note:In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.CitationWalter Reade and Elizabeth Park. Predict the Introverts from the Extroverts. https://kaggle.com/competitions/playground-series-s5e7, 2025. Kaggle.CiteCompetition HostKagglePrizes & AwardsSwagDoes not award Points or MedalsParticipation9,401 Entrants4,447 Participants4,329 Teams29,210 SubmissionsTagsBeginnerTabularAccuracy Score\n\nData description:\nPlayground Series - Season 5, Episode 7  \nPredict the Introverts from the Extroverts  \n\nDataset Description  \nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Extrovert vs. Introvert Behavior dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.  \nNote- This is a relatively small dataset, so a one to use for comparing different modeling approaches, making visualization, etc.  \n\nFiles  \ntrain.csv - the training dataset; Personality is the categorical target  \ntest.csv - the test dataset; your objective is to predict the Personality for each row  \nsample_submission.csv - a sample submission file in the correct format  \n\nMetadata  \nLicense CC BY-SA 4.0",
      "docker_challenge_path": "/data/playground-series-s5e7",
      "competition_description": "OverviewWelcome to the 2025 Kaggle Playground Series!We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.Your Goal:Your objective is to predict whether a person is an Introvert or Extrovert, given their social behavior and personality traits.",
      "evaluation_metric": "EvaluationSubmissions are evaluated usingAccuracy Scorebetween the predicted value and the observed target.",
      "dataset_description": "Playground Series - Season 5, Episode 7  \nPredict the Introverts from the Extroverts  \n\nDataset Description  \nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Extrovert vs. Introvert Behavior dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.  \nNote- This is a relatively small dataset, so a one to use for comparing different modeling approaches, making visualization, etc.  \n\nFiles  \ntrain.csv - the training dataset; Personality is the categorical target  \ntest.csv - the test dataset; your objective is to predict the Personality for each row  \nsample_submission.csv - a sample submission file in the correct format  \n\nMetadata  \nLicense CC BY-SA 4.0",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "classification",
          "tabular",
          "feature engineering",
          "social-psychology",
          "accuracy"
        ]
      }
    },
    {
      "challenge_name": "playground-series-s5e8",
      "description": "Challenge description:\nPlayground Series - Season 5, Episode 8\nBinary Classification with a Bank Dataset\n\nOverview\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\nYour Goal: Your goal is to predict whether a client will subscribe to a bank term deposit.\n\nEvaluation\nSubmissions are evaluated using ROC AUC between the predicted value and the observed target.\nSubmission File\nFor each id in the test set, you must predict the probability of the binary target y. The file should contain a header and have the following format:\nid,y\n750000,0.5\n750001,0.5\n750002,0.5\netc.\n\nTimeline\nStart Date - August 1, 2025\nEntry Deadline - Same as the Final Submission Deadline\nTeam Merger Deadline - Same as the Final Submission Deadline\nFinal Submission Deadline - August 31, 2025\nAll deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n\nAbout the Tabular Playground Series\nThe goal of the Tabular Playground Series is to provide the Kaggle community with a variety of fairly light-weight challenges that can be used to learn and sharpen skills in different aspects of machine learning and data science. The duration of each competition will generally only last a few weeks, and may have longer or shorter durations depending on the challenge. The challenges will generally use fairly light-weight datasets that are synthetically generated from real-world data, and will provide an opportunity to quickly iterate through various model and feature engineering ideas, create visualizations, etc.\nSynthetically-Generated Datasets\nUsing synthetic data for Playground competitions allows us to strike a balance between having real-world data (with named features) and ensuring test labels are not publicly available. This allows us to host competitions with more interesting datasets than in the past. While there are still challenges with synthetic data generation, the state-of-the-art is much better now than when we started the Tabular Playground Series two years ago, and that goal is to produce datasets that have far fewer artifacts. Please feel free to give us feedback on the datasets for the different competitions so that we can continue to improve!\n\nPrizes\n1st Place - Choice of Kaggle merchandise\n2nd Place - Choice of Kaggle merchandise\n3rd Place - Choice of Kaggle merchandise\nPlease note: In order to encourage more participation from beginners, Kaggle merchandise will only be awarded once per person in this series. If a person has previously won, we'll skip to the next team.\nDoes not award Points or Medals\n\nCitation\nWalter Reade and Elizabeth Park. Binary Classification with a Bank Dataset. https://kaggle.com/competitions/playground-series-s5e8, 2025. Kaggle.\n\nCompetition Host\nKaggle\n\nData description:\nPlayground Series - Season 5, Episode 8\nBinary Classification with a Bank Dataset\n\nDataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Bank Marketing Dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; 'y' is the binary target\ntest.csv - the test dataset; your objective is to predict the probability of 'y' for each row\nsample_submission.csv - a sample submission file in the correct format\n\nMetadata\nLicense: Apache 2.0",
      "docker_challenge_path": "/data/playground-series-s5e8",
      "competition_description": "Challenge description:\nPlayground Series - Season 5, Episode 8\nBinary Classification with a Bank Dataset\n\nOverview\nWelcome to the 2025 Kaggle Playground Series! We plan to continue in the spirit of previous playgrounds, providing interesting and approachable datasets for our community to practice their machine learning skills, and anticipate a competition each month.\nYour Goal: Your goal is to predict whether a client will subscribe to a bank term deposit.",
      "evaluation_metric": "Evaluation\nSubmissions are evaluated using ROC AUC between the predicted value and the observed target.",
      "dataset_description": "Dataset Description\nThe dataset for this competition (both train and test) was generated from a deep learning model trained on the Bank Marketing Dataset. Feature distributions are close to, but not exactly the same, as the original. Feel free to use the original dataset as part of this competition, both to explore differences as well as to see whether incorporating the original in training improves model performance.\n\nFiles\ntrain.csv - the training dataset; 'y' is the binary target\ntest.csv - the test dataset; your objective is to predict the probability of 'y' for each row\nsample_submission.csv - a sample submission file in the correct format\n\nMetadata\nLicense: Apache 2.0",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "binary classification",
          "tabular",
          "feature engineering",
          "banking",
          "auc"
        ]
      }
    },
    {
      "challenge_name": "titanic",
      "description": "Challenge description:\n# Titanic - Machine Learning from Disaster\n\n## Description\n\n\ud83d\udc4b\ud83d\udef3\ufe0f Ahoy, welcome to Kaggle! You're in the right place.\n\nThis is the legendary Titanic ML competition \u2013 the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\n### The Challenge\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \"unsinkable\" RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren't enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \"what sorts of people were more likely to survive?\" using passenger data (ie name, age, gender, socio-economic class, etc).\n\n### What Data Will I Use in This Competition?\n\nIn this competition, you'll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled train.csv and the other is titled test.csv.\n\nTrain.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the \"ground truth\".\n\nThe test.csv dataset contains similar information but does not disclose the \"ground truth\" for each passenger. It's your job to predict these outcomes.\n\nUsing the patterns you find in the train.csv data, predict whether the other 418 passengers on board (found in test.csv) survived.\n\n### How to Submit your Prediction to Kaggle\n\nOnce you're ready to make a submission and get on the leaderboard:\n\nClick on the \"Submit Predictions\" button\nUpload a CSV file in the submission file format. You're able to submit 10 submissions a day.\n\n#### Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.\n\nThe file should have exactly 2 columns:\n- PassengerId (sorted in any order)\n- Survived (contains your binary predictions: 1 for survived, 0 for deceased)\n\nPassengerId,Survived\n892,0\n893,1\n894,0\nEtc.\n\nYou can download an example submission file (gender_submission.csv) on the Data page.\n\n## Evaluation\n\n### Goal\nIt is your job to predict if a passenger survived the sinking of the Titanic or not.\nFor each passenger in the test set, you must predict a 0 or 1 value for the Survived variable.\n\n### Metric\nYour score is the percentage of passengers you correctly predict. This is known as accuracy.\n\n## Frequently Asked Questions\n\n### What is a Getting Started competition?\nGetting Started competitions were created by Kaggle data scientists for people who have little to no machine learning background. They are a great place to begin if you are new to data science or just finished a MOOC and want to get involved in Kaggle.\n\nGetting Started competitions are a non-competitive way to get familiar with Kaggle's platform, learn basic machine learning concepts, and start meeting people in the community. They have no cash prize and are on a rolling timeline.\n\n### How do I create and manage a team?\nWhen you accept the competition rules, a team will be created for you. You can invite others to your team, accept a merger with another team, and update basic information like team name by going to the More > Team page.\n\nWe've heard from many Kagglers that teaming up is the best way to learn new skills AND have fun. If you don't have a teammate already, consider asking if anyone wants to team up in the discussion forum.\n\n### What are Notebooks?\nKaggle Notebooks is a cloud computational environment that enables reproducible and collaborative analysis. Notebooks support scripts in Python and R, Jupyter Notebooks, and RMarkdown reports. You can visit the Notebooks tab to view all of the publicly shared code for the Titanic competition.\n\n### Why did my team disappear from the leaderboard?\nTo keep with the spirit of getting-started competitions, we have implemented a two month rolling window on submissions. Once a submission is more than two months old, it will be invalidated and no longer count towards the leaderboard.\n\nIf your team has no submissions in the previous two months, the team will also drop from the leaderboard. This will keep the leaderboard at a manageable size, freshen it up, and prevent newcomers from getting lost in a sea of abandoned scores.\n\n### How do I contact Support?\nKaggle does not have a dedicated support team so you'll typically find that you receive a response more quickly by asking your question in the appropriate forum. (For this competition, you'll want to use the Titanic discussion forum).\n\nSupport is only able to help with issues that are being experienced by all participants. Before contacting support, please check the discussion forum for information on your problem. If you can't find it, you can post your problem in the forum so a fellow participant or a Kaggle team member can provide help.\n\nIf your problem persists or it seems to be affecting all participants then please contact us.\n\n## Citation\n\nWill Cukierski. Titanic - Machine Learning from Disaster. https://kaggle.com/competitions/titanic, 2012. Kaggle.\n\n## Competition Details\n\n**Competition Host**: Kaggle\n\n**Prizes & Awards**: Does not award Points or Medals\n\n**Participation**:\n- 1,398,236 Entrants\n- 13,164 Participants\n- 13,128 Teams\n- 45,442 Submissions\n\n**Tags**: Binary Classification, Tabular, Beginner, Categorization Accuracy\n\n**Timeline**: This competition runs indefinitely with a rolling leaderboard.\n\nData description:\nTitanic - Machine Learning from Disaster\nStart here! Predict survival on the Titanic and get familiar with ML basics\n\nDataset Description\nOverview\nThe data has been split into two groups:\ntraining set (train.csv)\ntest set (test.csv)\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You can also use feature engineering to create new features.\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\nWe also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n\nData Dictionary\nVariableDefinitionKey\nsurvivalSurvival0 = No, 1 = Yes\npclassTicket class1 = 1st, 2 = 2nd, 3 = 3rd\nsexSex\nageAge in years\nsibsp# of siblings / spouses aboard the Titanic\nparch# of parents / children aboard the Titanic\nticketTicket number\nfarePassenger fare\ncabinCabin number\nembarkedPort of EmbarkationC = Cherbourg, Q = Queenstown, S = Southampton\n\nVariable Notes\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.\n\nLicenseSubject to Competition Rules",
      "docker_challenge_path": "/data/titanic",
      "competition_description": "Challenge description:\n# Titanic - Machine Learning from Disaster\n\n## Description\n\n\ud83d\udc4b\ud83d\udef3\ufe0f Ahoy, welcome to Kaggle! You're in the right place.\n\nThis is the legendary Titanic ML competition \u2013 the best, first challenge for you to dive into ML competitions and familiarize yourself with how the Kaggle platform works.\n\nThe competition is simple: use machine learning to create a model that predicts which passengers survived the Titanic shipwreck.\n\n### The Challenge\n\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \"unsinkable\" RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren't enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \"what sorts of people were more likely to survive?\" using passenger data (ie name, age, gender, socio-economic class, etc).\n\n### What Data Will I Use in This Competition?\n\nIn this competition, you'll gain access to two similar datasets that include passenger information like name, age, gender, socio-economic class, etc. One dataset is titled train.csv and the other is titled test.csv.\n\nTrain.csv will contain the details of a subset of the passengers on board (891 to be exact) and importantly, will reveal whether they survived or not, also known as the \"ground truth\".\n\nThe test.csv dataset contains similar information but does not disclose the \"ground truth\" for each passenger. It's your job to predict these outcomes.\n\nUsing the patterns you find in the train.csv data, predict whether the other 418 passengers on board (found in test.csv) survived.\n\n### How to Submit your Prediction to Kaggle\n\nOnce you're ready to make a submission and get on the leaderboard:\n\nClick on the \"Submit Predictions\" button\nUpload a CSV file in the submission file format. You're able to submit 10 submissions a day.\n\n#### Submission File Format:\nYou should submit a csv file with exactly 418 entries plus a header row. Your submission will show an error if you have extra columns (beyond PassengerId and Survived) or rows.\n\nThe file should have exactly 2 columns:\n- PassengerId (sorted in any order)\n- Survived (contains your binary predictions: 1 for survived, 0 for deceased)\n\nPassengerId,Survived\n892,0\n893,1\n894,0\nEtc.\n\nYou can download an example submission file (gender_submission.csv) on the Data page.",
      "evaluation_metric": "### Metric\nYour score is the percentage of passengers you correctly predict. This is known as accuracy.",
      "dataset_description": "Data description:\nTitanic - Machine Learning from Disaster\nStart here! Predict survival on the Titanic and get familiar with ML basics\n\nDataset Description\nOverview\nThe data has been split into two groups:\ntraining set (train.csv)\ntest set (test.csv)\nThe training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You can also use feature engineering to create new features.\nThe test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\nWe also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.\n\nData Dictionary\nVariableDefinitionKey\nsurvivalSurvival0 = No, 1 = Yes\npclassTicket class1 = 1st, 2 = 2nd, 3 = 3rd\nsexSex\nageAge in years\nsibsp# of siblings / spouses aboard the Titanic\nparch# of parents / children aboard the Titanic\nticketTicket number\nfarePassenger fare\ncabinCabin number\nembarkedPort of EmbarkationC = Cherbourg, Q = Queenstown, S = Southampton\n\nVariable Notes\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.\n\nLicenseSubject to Competition Rules",
      "metadata": {
        "domain": "machine_learning",
        "keywords": [
          "classification",
          "tabular",
          "feature engineering",
          "demographics",
          "accuracy"
        ]
      }
    }
  ]